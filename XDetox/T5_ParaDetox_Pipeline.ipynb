{"cells":[{"cell_type":"markdown","metadata":{"id":"flSJi4XFC5Lf"},"source":["# T5-ParaDetox Pipeline\n","This notebook mirrors the XDetox_Pipeline structure for direct comparison:\n","\n","- **Small-batch runs**: choose how many examples to process\n","- **Dataset picker**: run a single dataset or **all**\n","- **Same datasets** as XDetox (paradetox, microagressions, sbf, dynabench, jigsaw, appdia)\n","- **Same evaluation metrics** (BLEU, BERTScore, Perplexity, Toxicity)\n","- **Same output format** (CSV summaries)\n","\n","\u003e **Prereqs**: You have the trained T5 model checkpoint on Drive and datasets available."]},{"cell_type":"markdown","metadata":{"id":"1xEP_aB-C5Lr"},"source":["## Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26821,"status":"ok","timestamp":1764846464933,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"gZ9T64FgC5Lt","outputId":"16777257-24d7-4d73-eb0f-1b47558b7112"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","PROJECT_BASE: /content/drive/MyDrive/w266 - Project\n","XDETOX_DIR: /content/drive/MyDrive/w266 - Project/XDetox -\u003e True\n","T5_CHECKPOINT: /content/drive/MyDrive/w266 - Project/t5-base-detox-model\n","TRANSFORMERS_CACHE: /content/drive/MyDrive/w266 - Project/XDetox/cache\n","CUDA available: False\n"]}],"source":["#@title Mount Drive \u0026 locate XDetox (baseline T5 pipeline)\n","from google.colab import drive; drive.mount('/content/drive')\n","\n","import os, sys, torch\n","\n","# Base paths (aligned with DecompX pipeline)\n","PROJECT_BASE = \"/content/drive/MyDrive/w266 - Project\"\n","XDETOX_DIR   = os.path.join(PROJECT_BASE, \"XDetox\")\n","T5_CHECKPOINT = os.path.join(PROJECT_BASE, \"t5-base-detox-model\")\n","\n","print(\"PROJECT_BASE:\", PROJECT_BASE)\n","print(\"XDETOX_DIR:\", XDETOX_DIR, \"-\u003e\", os.path.isdir(XDETOX_DIR))\n","print(\"T5_CHECKPOINT:\", T5_CHECKPOINT)\n","\n","assert os.path.isdir(XDETOX_DIR), f\"XDETOX_DIR does not exist: {XDETOX_DIR}\"\n","assert os.path.isdir(T5_CHECKPOINT), f\"T5_CHECKPOINT does not exist: {T5_CHECKPOINT}\"\n","\n","# Runtime setup (paths, cache, GPU)\n","HF_CACHE = os.path.join(XDETOX_DIR, \"cache\")\n","os.makedirs(HF_CACHE, exist_ok=True)\n","os.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","if XDETOX_DIR not in sys.path:\n","    sys.path.append(XDETOX_DIR)\n","\n","print(\"TRANSFORMERS_CACHE:\", HF_CACHE)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))\n","\n","REPO = XDETOX_DIR       # used by evaluate_all\n","DATASET_BASE = REPO     # datasets live under XDetox\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48477,"status":"ok","timestamp":1764846513421,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"6hf-KGmAC5Ly","outputId":"0b379e91-a33c-472c-d7b9-05d871cdf1a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi\u003e=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#@title Install dependencies (aligned with DecompX pipeline)\n","!pip -q install --upgrade pip setuptools wheel\n","!pip -q install \"transformers==4.41.2\" \"tokenizers==0.19.1\" \\\n","                \"datasets==2.19.0\" \"evaluate==0.4.1\" \\\n","                \"sacrebleu==2.4.1\" sacremoses ftfy nltk matplotlib pandas jedi \\\n","                sentencepiece\n","!pip -q install bert-score\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17328,"status":"ok","timestamp":1764846530753,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"e7HZtFE9C5L0","outputId":"0a87df62-216d-494a-b134-a867bc223e53"},"outputs":[{"name":"stdout","output_type":"stream","text":["NLTK ready\n"]}],"source":["#@title NLTK data\n","import nltk\n","nltk.download(\"punkt\", quiet=True)\n","try:\n","    nltk.download(\"punkt_tab\", quiet=True)\n","except Exception:\n","    pass\n","print(\"NLTK ready\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7346,"status":"ok","timestamp":1764846538095,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"8pgdv2hxC5L1","outputId":"7b94052e-ee45-4c95-a9d4-011b10eda7a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["✓ Libraries imported\n"]}],"source":["#@title Imports\n","import glob, re, json, shutil, math\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from subprocess import run, PIPE\n","from typing import List\n","\n","from transformers import (\n","    T5Tokenizer,\n","    T5ForConditionalGeneration,\n",")\n","\n","print(\"✓ Libraries imported\")\n"]},{"cell_type":"markdown","metadata":{"id":"mRsbxUmAC5L5"},"source":["## Dataset Configuration"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1764846538174,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"V2-tzreZC5L7","outputId":"e4f04730-e986-40c9-f837-8b6d7adfa625"},"outputs":[{"name":"stdout","output_type":"stream","text":["7 datasets configured: paradetox, microagressions_test, sbf_test, dynabench_test, jigsaw_toxic, appdia_original, appdia_discourse\n"]}],"source":["## Dataset Configuration\n","\n","#@title Data configs (matching XDetox datasets)\n","data_configs = {\n","    \"paradetox\": {\n","        \"data_path\": \"./datasets/paradetox/test_toxic_parallel.txt\",\n","        \"format\": \"txt\",\n","    },\n","    \"microagressions_test\": {\n","        \"data_path\": \"./datasets/microagressions/test.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"sbf_test\": {\n","        \"data_path\": \"./datasets/sbf/sbftst.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"dynabench_test\": {\n","        \"data_path\": \"./datasets/dynabench/db_test.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"jigsaw_toxic\": {\n","        \"data_path\": \"./datasets/jigsaw_full_30/test_10k_toxic.txt\",\n","        \"format\": \"txt\",\n","    },\n","    \"appdia_original\": {\n","        \"data_path\": \"./datasets/appdia/original-annotated-data/original-test.tsv\",\n","        \"format\": \"tsv\",\n","    },\n","    \"appdia_discourse\": {\n","        \"data_path\": \"./datasets/appdia/discourse-augmented-data/discourse-test.tsv\",\n","        \"format\": \"tsv\",\n","    },\n","}\n","print(f\"{len(data_configs)} datasets configured:\", \", \".join(data_configs.keys()))\n"]},{"cell_type":"markdown","metadata":{"id":"l6_6TXaGC5L9"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1764846538308,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"B0S8ot-1C5L9","outputId":"98724250-6a09-46a9-c36a-eb74e3aa53ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["✓ Helper functions loaded\n"]}],"source":["## Helper Functions\n","\n","#@title Helper functions\n","\n","def _ensure_dir(p: str):\n","    Path(p).mkdir(parents=True, exist_ok=True)\n","\n","def load_test_data(data_type: str, num_examples: int = None) -\u003e List[str]:\n","    \"\"\"\n","    Load test data from .txt / .csv / .tsv.\n","    Returns a list of toxic texts as strings.\n","    \"\"\"\n","    if data_type not in data_configs:\n","        raise ValueError(f\"Unknown data_type: {data_type}\")\n","\n","    cfg = data_configs[data_type]\n","    data_path = os.path.join(DATASET_BASE, cfg[\"data_path\"].lstrip(\"./\"))\n","\n","    texts = []\n","\n","    if cfg[\"format\"] == \"txt\":\n","        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n","            texts = [line.strip() for line in f if line.strip()]\n","\n","    elif cfg[\"format\"] == \"csv\":\n","        df = pd.read_csv(data_path)\n","        if \"text\" in df.columns:\n","            texts = df[\"text\"].tolist()\n","        elif \"toxic\" in df.columns:\n","            texts = df[\"toxic\"].tolist()\n","        else:\n","            texts = df.iloc[:, 0].tolist()\n","\n","    elif cfg[\"format\"] == \"tsv\":\n","        df = pd.read_csv(data_path, sep=\"\\t\")\n","        if \"text\" in df.columns:\n","            texts = df[\"text\"].tolist()\n","        else:\n","            texts = df.iloc[:, 0].tolist()\n","\n","    cleaned = []\n","    for t in texts:\n","        if pd.isna(t):\n","            continue\n","        s = str(t).strip()\n","        if s:\n","            cleaned.append(s)\n","\n","    if num_examples and num_examples \u003e 0:\n","        cleaned = cleaned[:num_examples]\n","\n","    return cleaned\n","\n","def _safe_float(x):\n","    try:\n","        return float(x)\n","    except Exception:\n","        return float(\"nan\")\n","\n","def _read_stats_file(path: str) -\u003e dict:\n","    out = {}\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            if \":\" not in line:\n","                continue\n","            k, v = line.strip().split(\": \", 1)\n","            k = k.replace(\"(skipped)\", \"\").strip().lower()\n","            out[k] = _safe_float(v)\n","    return out\n","\n","print(\"✓ Helper functions loaded\")\n"]},{"cell_type":"markdown","metadata":{"id":"dyHQiqbxC5L_"},"source":["## T5 Model Loading"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29593,"status":"ok","timestamp":1764846567905,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"PlPYvKZgC5L_","outputId":"04cc08b4-648f-43ba-d103-04d3c154b842"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading T5 model from /content/drive/MyDrive/w266 - Project/t5-base-detox-model...\n"]},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["✓ T5 model loaded on cpu\n"]}],"source":["## T5 Model Loading\n","\n","#@title Load T5 model (ParaDetox baseline)\n","print(f\"Loading T5 model from {T5_CHECKPOINT}...\")\n","\n","t5_tokenizer = T5Tokenizer.from_pretrained(T5_CHECKPOINT)\n","t5_model = T5ForConditionalGeneration.from_pretrained(T5_CHECKPOINT)\n","t5_model.eval()\n","\n","DEVICE_T5 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","t5_model.to(DEVICE_T5)\n","\n","print(f\"✓ T5 model loaded on {DEVICE_T5}\")\n"]},{"cell_type":"markdown","metadata":{"id":"WhxGPScEC5MA"},"source":["## T5 Inference Function"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13308,"status":"ok","timestamp":1764846581201,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"TQWFFFZBC5MB","outputId":"40d5a5fa-b9b5-4c8f-d133-70f604550397"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test input: This is a stupid idea\n","Detoxified: This is a bad idea\n"]}],"source":["#@title T5 generation functions (single + batch)\n","\n","def t5_detoxify_text(\n","    text: str,\n","    model: T5ForConditionalGeneration,\n","    tokenizer: T5Tokenizer,\n","    max_length: int = 128,\n","    num_beams: int = 5,\n","    device: torch.device = DEVICE_T5,\n",") -\u003e str:\n","    \"\"\"\n","    Generate one detoxified text with beam search.\n","    \"\"\"\n","    input_text = f\"detoxify: {text}\"\n","    input_ids = tokenizer.encode(\n","        input_text,\n","        return_tensors=\"pt\",\n","        max_length=max_length,\n","        truncation=True,\n","    ).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_beams=num_beams,\n","            early_stopping=True,\n","            no_repeat_ngram_size=2,\n","        )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","def t5_detoxify_batch(\n","    texts: List[str],\n","    model: T5ForConditionalGeneration,\n","    tokenizer: T5Tokenizer,\n","    max_length: int = 128,\n","    num_beams: int = 5,\n","    batch_size: int = 8,\n","    device: torch.device = DEVICE_T5,\n",") -\u003e List[str]:\n","    \"\"\"\n","    Batch inference for efficiency.\n","    \"\"\"\n","    outputs_all: List[str] = []\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"T5 Generation\"):\n","        batch_texts = texts[i:i + batch_size]\n","        prompts = [f\"detoxify: {t}\" for t in batch_texts]\n","\n","        enc = tokenizer(\n","            prompts,\n","            return_tensors=\"pt\",\n","            max_length=max_length,\n","            truncation=True,\n","            padding=True,\n","        ).to(device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **enc,\n","                max_length=max_length,\n","                num_beams=num_beams,\n","                early_stopping=True,\n","                no_repeat_ngram_size=2,\n","            )\n","\n","        decoded = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n","        outputs_all.extend(decoded)\n","\n","    return outputs_all\n","\n","# Quick sanity check\n","test_text = \"This is a stupid idea\"\n","detoxified = t5_detoxify_text(test_text, t5_model, t5_tokenizer, device=DEVICE_T5)\n","print(f\"Test input: {test_text}\")\n","print(f\"Detoxified: {detoxified}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Bt0wA1kwC5MC"},"source":["## Evaluation Functions"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1764846581241,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"O6tJqcBJC5MC","outputId":"7fa89469-157c-4623-f270-71ac7d568a44"},"outputs":[{"name":"stdout","output_type":"stream","text":["✓ Evaluation helpers defined\n"]}],"source":["## Evaluation helpers (evaluate_all.py, same style as DecompX)\n","\n","#@title Evaluation helpers (evaluate_all.py + CSV aggregation)\n","\n","def _eval_with_toxicity(\n","    base_path: str,\n","    overwrite_eval: bool = False,\n","    skip_ref: bool = False,\n","    tox_threshold: float = 0.5,\n","    tox_batch_size: int = 32,\n","):\n","    \"\"\"\n","    Call evaluation.evaluate_all on each run folder in base_path.\n","    Same pattern as DecompX pipeline.\n","    \"\"\"\n","    import sys as _sys\n","    for folder in os.listdir(base_path):\n","        gen_dir = os.path.join(base_path, folder)\n","        if not os.path.isdir(gen_dir):\n","            continue\n","        orig_path = os.path.join(gen_dir, \"orig.txt\")\n","        gen_path  = os.path.join(gen_dir, \"gen.txt\")\n","        out_stats = os.path.join(gen_dir, \"gen_stats.txt\")\n","        if not (os.path.exists(orig_path) and os.path.exists(gen_path)):\n","            continue\n","        if os.path.exists(out_stats) and not overwrite_eval:\n","            continue\n","\n","        env = os.environ.copy()\n","        env[\"PYTHONPATH\"] = REPO + (\n","            \":\" + env.get(\"PYTHONPATH\", \"\") if env.get(\"PYTHONPATH\") else \"\"\n","        )\n","        cmd = [\n","            _sys.executable, \"-m\", \"evaluation.evaluate_all\",\n","            \"--orig_path\", orig_path,\n","            \"--gen_path\",  gen_path,\n","            \"--tox_threshold\", str(tox_threshold),\n","            \"--tox_batch_size\", str(tox_batch_size),\n","        ]\n","        if skip_ref:\n","            cmd.append(\"--skip_ref\")\n","        print(\"Eval:\", \" \".join(cmd))\n","        res = run(cmd, cwd=REPO, env=env, stdout=PIPE, stderr=PIPE, text=True)\n","        if res.returncode != 0:\n","            print(res.stdout)\n","            print(res.stderr)\n","            res.check_returncode()\n","\n","def _aggregate_eval_csv_baseline(\n","    output_folder: str,\n","    data_type: str,\n","    base_out_dir: str,\n","    model_dir: str = \"T5_Baseline\",\n","):\n","    \"\"\"\n","    Aggregate eval metrics for T5 ParaDetox baseline (no reranking).\n","\n","    Layout (absolute base_out_dir):\n","      base_out_dir/\n","        └── {data_type}/\n","            └── {model_dir}/\n","                └── {run_folder}/\n","                    └── gen_stats.txt\n","    \"\"\"\n","    rows = []\n","\n","    base_path = os.path.join(base_out_dir, data_type, model_dir)\n","    if not os.path.isdir(base_path):\n","        print(\"No evaluation directory found:\", base_path)\n","        return\n","\n","    for folder in os.listdir(base_path):\n","        gen_dir    = os.path.join(base_path, folder)\n","        stats_path = os.path.join(gen_dir, \"gen_stats.txt\")\n","        if not os.path.exists(stats_path):\n","            continue\n","        s = _read_stats_file(stats_path)\n","        rows.append({\n","            \"folder\":          folder,\n","            \"bertscore\":       s.get(\"bertscore\", np.nan),\n","            \"meaningbert\":     s.get(\"meaningbert\", np.nan),\n","            \"bleu4\":           s.get(\"bleu4\", np.nan),\n","            \"perplexity_gen\":  s.get(\"perplexity gen\", np.nan),\n","            \"perplexity_orig\": s.get(\"perplexity orig\", np.nan),\n","            \"toxicity_gen\":    s.get(\"toxicity gen\", np.nan),\n","            \"toxicity_orig\":   s.get(\"toxicity orig\", np.nan),\n","        })\n","\n","    if rows:\n","        cols = [\n","            \"folder\",\n","            \"bertscore\", \"meaningbert\", \"bleu4\",\n","            \"perplexity_gen\", \"perplexity_orig\",\n","            \"toxicity_gen\", \"toxicity_orig\",\n","        ]\n","        df = pd.DataFrame(rows)\n","        df = df[cols]\n","        out_csv = os.path.join(base_out_dir, data_type, f\"{data_type}.csv\")\n","        _ensure_dir(os.path.dirname(out_csv))\n","        df.to_csv(out_csv, index=False)\n","        print(\"Wrote summary CSV:\", out_csv)\n","    else:\n","        print(\"No evaluation files found to summarize.\")\n","\n","print(\"✓ Evaluation helpers defined\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1764846581252,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"GGjZtWDLC5ME","outputId":"5eb126ef-9cdf-45c0-d21f-8bb8bda135e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["✓ Folder-naming helper defined\n"]}],"source":["#@title Helpers for folder naming\n","\n","def _build_run_folder_name_t5_baseline(\n","    max_length: int,\n","    num_beams: int,\n",") -\u003e str:\n","    \"\"\"\n","    Build a folder name encoding T5 baseline hyperparameters.\n","    \"\"\"\n","    return f\"t5_baseline_maxlen{max_length}_beams{num_beams}\"\n","\n","print(\"✓ Folder-naming helper defined\")\n"]},{"cell_type":"markdown","metadata":{"id":"ujgMqtl6C5MF"},"source":["## Main Pipeline Function"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1764846581321,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"08ro8C5iC5MF","outputId":"6f9e4eec-01f8-49b1-fb18-58c21224288a"},"outputs":[{"name":"stdout","output_type":"stream","text":["✓ detoxify_baseline() defined\n"]}],"source":["#@title detoxify_baseline() — T5 ParaDetox + evaluate_all\n","\n","def detoxify_baseline(\n","    data_type: str = \"paradetox\",\n","    output_folder: str = \"T5_Paradetox_Pipeline\",\n","    echo: bool = False,\n","    num_examples: int = 1000,\n","    batch_size: int = 8,\n","    max_length: int = 128,\n","    num_beams: int = 5,\n","    overwrite_gen: bool = False,\n","    run_eval: bool = True,\n","    overwrite_eval: bool = False,\n","    skip_ref_eval: bool = False,\n","):\n","    \"\"\"\n","    T5 ParaDetox baseline + evaluate_all.py\n","\n","    Steps:\n","      1. Load toxic inputs.\n","      2. Generate 1 candidate per input with T5 (beam search).\n","      3. Save orig.txt and gen.txt under:\n","         data/model_outputs/{output_folder}/{data_type}/T5_Baseline/{run_folder}/\n","      4. Run evaluation via evaluation.evaluate_all.py.\n","      5. Aggregate per-dataset CSV like DecompX pipeline.\n","    \"\"\"\n","    assert data_type in data_configs, f\"Unknown data_type: {data_type}\"\n","\n","    # Base output relative to repo (same style as DecompX pipeline)\n","    base_out_rel = os.path.join(\"data\", \"model_outputs\", output_folder)\n","    base_out_abs = os.path.join(REPO, base_out_rel)\n","    _ensure_dir(base_out_abs)\n","\n","    # Load data\n","    print(\"=\" * 80)\n","    print(f\"[{data_type}] Loading data...\")\n","    orig_texts = load_test_data(data_type, num_examples)\n","    print(f\"  Loaded {len(orig_texts)} examples\")\n","\n","    if echo:\n","        print(\"\\n[echo] Example inputs (first up to 3):\")\n","        for i, s in enumerate(orig_texts[:3]):\n","            print(f\"  input[{i}]: {s}\")\n","        print(f\"\\n[echo] num_beams: {num_beams}\")\n","        print(f\"[echo] max_length: {max_length}\")\n","\n","    # Directory for this pipeline (T5 baseline)\n","    model_dir = \"T5_Baseline\"\n","    cur_rel = os.path.join(base_out_rel, data_type, model_dir)\n","    cur_abs = os.path.join(REPO, cur_rel)\n","    _ensure_dir(cur_abs)\n","\n","    # Run-folder name for current hyperparameters\n","    run_folder = _build_run_folder_name_t5_baseline(\n","        max_length=max_length,\n","        num_beams=num_beams,\n","    )\n","    final_abs = os.path.join(cur_abs, run_folder)\n","    _ensure_dir(final_abs)\n","\n","    orig_path  = os.path.join(final_abs, \"orig.txt\")\n","    gen_path   = os.path.join(final_abs, \"gen.txt\")\n","    stats_path = os.path.join(final_abs, \"gen_stats.txt\")\n","\n","    # Generate or reuse outputs\n","    if overwrite_gen or not os.path.exists(gen_path):\n","        print(\"  Generating T5 outputs...\")\n","        gen_texts = t5_detoxify_batch(\n","            texts=orig_texts,\n","            model=t5_model,\n","            tokenizer=t5_tokenizer,\n","            max_length=max_length,\n","            num_beams=num_beams,\n","            batch_size=batch_size,\n","            device=DEVICE_T5,\n","        )\n","\n","        if echo and gen_texts:\n","            print(\"\\n[echo] Example generations (first up to 3):\")\n","            for i, g in enumerate(gen_texts[:3]):\n","                print(f\"  gen[{i}]: {g}\")\n","\n","        # Save orig and gen\n","        with open(orig_path, \"w\") as f:\n","            for t in orig_texts:\n","                f.write(re.sub(r\"\\s+\", \" \", t).strip() + \"\\n\")\n","        with open(gen_path, \"w\") as f:\n","            for t in gen_texts:\n","                f.write(re.sub(r\"\\s+\", \" \", t).strip() + \"\\n\")\n","\n","        print(\"  Saved orig/gen to:\", final_abs)\n","    else:\n","        print(\"  Reusing existing orig/gen from:\", final_abs)\n","        with open(orig_path, \"r\") as f:\n","            orig_texts = [l.strip() for l in f]\n","        with open(gen_path, \"r\") as f:\n","            gen_texts = [l.strip() for l in f]\n","        print(f\"  Loaded {len(gen_texts)} generated examples\")\n","\n","    # Evaluation via evaluation/evaluate_all.py\n","    metrics = None\n","    if run_eval:\n","        base_path = os.path.join(base_out_abs, data_type, model_dir)\n","        _eval_with_toxicity(\n","            base_path,\n","            overwrite_eval=overwrite_eval,\n","            skip_ref=skip_ref_eval,\n","            tox_threshold=0.5,\n","            tox_batch_size=32,\n","        )\n","        _aggregate_eval_csv_baseline(\n","            output_folder,\n","            data_type,\n","            os.path.join(REPO, \"data\", \"model_outputs\", output_folder),\n","            model_dir=model_dir,\n","        )\n","\n","        if os.path.exists(stats_path):\n","            metrics = _read_stats_file(stats_path)\n","            if echo:\n","                print(\"\\n[echo] Evaluation metrics for this run:\")\n","                for k, v in metrics.items():\n","                    if isinstance(v, float) and math.isnan(v):\n","                        continue\n","                    print(f\"  {k}: {v:.4f}\")\n","        else:\n","            print(\"  gen_stats.txt not found for this run; no metrics to print.\")\n","\n","    print(\"=\" * 80)\n","    return metrics\n","\n","print(\"✓ detoxify_baseline() defined\")\n"]},{"cell_type":"markdown","metadata":{"id":"ZwSyLnQCC5MG"},"source":["## Run Evaluation on All Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":399},"id":"oqbPcQgGC5MH"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","[paradetox] Loading data...\n","  Loaded 671 examples\n","\n","[echo] Example inputs (first up to 3):\n","  input[0]: . or the loud ass one - thousand ton beast roaring towards you howling its horn .\n","  input[1]: mandated  and \" right fucking now \" would be good .\n","  input[2]: * neither * of my coworkers gave a shit when it came time to ditch mitch . ugh .\n","\n","[echo] num_beams: 5\n","[echo] max_length: 128\n","  Generating T5 outputs...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"607cec3e5e5741c1aeb0c89079529277","version_major":2,"version_minor":0},"text/plain":["T5 Generation:   0%|          | 0/84 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","[echo] Example generations (first up to 3):\n","  gen[0]: or the one thousand ton beast roaring towards you howling its horn .\n","  gen[1]: mandated and \" right now \" would be good .\n","  gen[2]: neither * of my coworkers cared when it came time to ditch mitch.\n","  Saved orig/gen to: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_baseline/paradetox/T5_Baseline/t5_baseline_maxlen128_beams5\n","Eval: /usr/bin/python3 -m evaluation.evaluate_all --orig_path /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_baseline/paradetox/T5_Baseline/t5_baseline_maxlen128_beams5/orig.txt --gen_path /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_baseline/paradetox/T5_Baseline/t5_baseline_maxlen128_beams5/gen.txt --tox_threshold 0.5 --tox_batch_size 32\n","Wrote summary CSV: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_baseline/paradetox/paradetox.csv\n","\n","[echo] Evaluation metrics for this run:\n","  bertscore: 0.9534\n","  meaningbert: 74.8410\n","  bleu4: 82.6520\n","  toxicity gen: 0.2034\n","  perplexity gen: 192.0700\n","  toxicity orig: 0.9253\n","  perplexity orig: 273.7500\n","  percent toxic gen: 0.2027\n","  percent toxic ref: 0.9285\n","================================================================================\n","\n","Paradetox metrics for this run:\n","  bertscore: 0.9534\n","  meaningbert: 74.8410\n","  bleu4: 82.6520\n","  toxicity gen: 0.2034\n","  perplexity gen: 192.0700\n","  toxicity orig: 0.9253\n","  perplexity orig: 273.7500\n","  percent toxic gen: 0.2027\n","  percent toxic ref: 0.9285\n"]}],"source":["#@title Example run on ParaDetox (baseline)\n","\n","metrics_paradetox = detoxify_baseline(\n","    data_type=\"paradetox\",\n","    output_folder=\"T5_baseline\",  # folder name under data/model_outputs\n","    echo=True,\n","    num_examples=1000,\n","    batch_size=8,\n","    max_length=128,\n","    num_beams=5,\n","    overwrite_gen=False,\n","    run_eval=True,\n","    overwrite_eval=True,\n","    skip_ref_eval=False,\n",")\n","\n","print(\"\\nParadetox metrics for this run:\")\n","if metrics_paradetox:\n","    for k, v in metrics_paradetox.items():\n","        if isinstance(v, float) and math.isnan(v):\n","            continue\n","        print(f\"  {k}: {v:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03b9de632cc343929917a6a536dcd7f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04850cd7fa954e8586274e9e8a54e5d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388aea942b0244a39a20a1e51a732011":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50308076fbfd4139b829da2fb3b2e3a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"607cec3e5e5741c1aeb0c89079529277":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0747dd0c2be414a8e5b135e9578fbc9","IPY_MODEL_85361f796f7a4b409e966867a4885a51","IPY_MODEL_6d0e826a57504d6f9281de175c5689af"],"layout":"IPY_MODEL_04850cd7fa954e8586274e9e8a54e5d5"}},"614259c7792d4a0383dd6162de437817":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d0e826a57504d6f9281de175c5689af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf24f04d5a74213b79b057ef6ad767a","placeholder":"​","style":"IPY_MODEL_03b9de632cc343929917a6a536dcd7f0","value":" 84/84 [16:09\u0026lt;00:00,  8.30s/it]"}},"85361f796f7a4b409e966867a4885a51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf2c71f72fd4c5183094353717ebf38","max":84,"min":0,"orientation":"horizontal","style":"IPY_MODEL_388aea942b0244a39a20a1e51a732011","value":84}},"baf24f04d5a74213b79b057ef6ad767a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0747dd0c2be414a8e5b135e9578fbc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_614259c7792d4a0383dd6162de437817","placeholder":"​","style":"IPY_MODEL_50308076fbfd4139b829da2fb3b2e3a4","value":"T5 Generation: 100%"}},"ccf2c71f72fd4c5183094353717ebf38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}