{"cells":[{"cell_type":"markdown","metadata":{"id":"flSJi4XFC5Lf"},"source":["# T5-ParaDetox Pipeline\n","This notebook mirrors the XDetox_Pipeline structure for direct comparison:\n","\n","- **Small-batch runs**: choose how many examples to process\n","- **Dataset picker**: run a single dataset or **all**\n","- **Same datasets** as XDetox (paradetox, microagressions, sbf, dynabench, jigsaw, appdia)\n","- **Same evaluation metrics** (BLEU, BERTScore, Perplexity, Toxicity)\n","- **Same output format** (CSV summaries)\n","\n","> **Prereqs**: You have the trained T5 model checkpoint on Drive and datasets available."]},{"cell_type":"markdown","metadata":{"id":"1xEP_aB-C5Lr"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZ9T64FgC5Lt","executionInfo":{"status":"ok","timestamp":1764024437839,"user_tz":480,"elapsed":58279,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"12fab62c-74e3-4f1a-fb32-aa2cec8c110e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Try PROJECT_BASE: /content/drive/MyDrive/ds266/w266 - Project -> True\n","Using PROJECT_BASE: /content/drive/MyDrive/ds266/w266 - Project\n"]}],"source":["#@title Mount Drive & locate project\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, glob, re, sys, torch, json, shutil, math, nltk\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","\n","# Set your project base path\n","PROJECT_BASE = \"/content/drive/MyDrive/ds266/w266 - Project\"\n","print(\"Try PROJECT_BASE:\", PROJECT_BASE, \"->\", os.path.isdir(PROJECT_BASE))\n","\n","assert os.path.isdir(PROJECT_BASE), f\"PROJECT_BASE does not exist: {PROJECT_BASE}\"\n","print(\"Using PROJECT_BASE:\", PROJECT_BASE)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hf-KGmAC5Ly","executionInfo":{"status":"ok","timestamp":1764024437863,"user_tz":480,"elapsed":17,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"84e3618e-45a9-4e20-d635-1560e171dc83"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROJECT_BASE: /content/drive/MyDrive/ds266/w266 - Project\n","T5_CHECKPOINT: /content/drive/MyDrive/ds266/w266 - Project/t5-base-detox-model\n","TRANSFORMERS_CACHE: /content/drive/MyDrive/ds266/w266 - Project/cache\n","CUDA available: False\n"]}],"source":["#@title Runtime setup (paths, cache, GPU)\n","# HuggingFace cache\n","HF_CACHE = os.path.join(PROJECT_BASE, \"cache\")\n","os.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# Model checkpoint path\n","T5_CHECKPOINT = os.path.join(PROJECT_BASE, \"t5-base-detox-model\")\n","\n","print(\"PROJECT_BASE:\", PROJECT_BASE)\n","print(\"T5_CHECKPOINT:\", T5_CHECKPOINT)\n","print(\"TRANSFORMERS_CACHE:\", HF_CACHE)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7HZtFE9C5L0","executionInfo":{"status":"ok","timestamp":1764024478432,"user_tz":480,"elapsed":40565,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"40629b57-7ee0-4ee4-d8e7-708cde772c41"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#@title Install dependencies\n","# Use Colab's pre-installed versions (no version pinning needed)\n","!pip install -q transformers torch datasets\n","!pip install -q evaluate sacrebleu bert-score\n","!pip install -q sentence-transformers\n","!pip install -q accelerate -U\n","!pip install -q rouge_score\n","!pip install -q pandas numpy scikit-learn matplotlib nltk"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pgdv2hxC5L1","executionInfo":{"status":"ok","timestamp":1764024479566,"user_tz":480,"elapsed":1128,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"5615ee36-aacd-45c8-d7d2-4b1c3f40bccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["NLTK ready\n"]}],"source":["#@title NLTK data\n","nltk.download(\"punkt\", quiet=True)\n","try:\n","    nltk.download(\"punkt_tab\", quiet=True)\n","except Exception:\n","    pass\n","print(\"NLTK ready\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a74asBeoC5L3","executionInfo":{"status":"ok","timestamp":1764024528306,"user_tz":480,"elapsed":48735,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"fc978a6c-5462-4c1a-aa04-fe61dc6a3237"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["✓ Libraries imported\n"]}],"source":["#@title Import libraries\n","from transformers import (\n","    T5Tokenizer,\n","    T5ForConditionalGeneration,\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    GPT2Tokenizer,\n","    GPT2LMHeadModel\n",")\n","from torch.utils.data import Dataset\n","from sentence_transformers import SentenceTransformer\n","from evaluate import load\n","from sklearn.model_selection import train_test_split\n","\n","print(\"✓ Libraries imported\")"]},{"cell_type":"markdown","metadata":{"id":"mRsbxUmAC5L5"},"source":["## Dataset Configuration"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2-tzreZC5L7","executionInfo":{"status":"ok","timestamp":1764026313384,"user_tz":480,"elapsed":82,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"31b397b9-1428-4f07-c538-120c98632705"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ 7 test datasets configured:\n","  - microagressions_test\n","  - sbf_test\n","  - dynabench_test\n","  - jigsaw_toxic\n","  - paradetox\n","  - appdia_original\n","  - appdia_discourse\n"]}],"source":["#@title Data configs (matching XDetox datasets)\n","# Note: For T5, we don't use XDetox-specific params (alpha_a, etc.)\n","# But we keep the same dataset paths for consistency\n","\n","# These paths are relative to XDetox repo - we'll need to adapt them\n","# For now, assume datasets are in a shared location accessible from both notebooks\n","\n","data_configs = {\n","    \"microagressions_test\": {\n","        \"data_path\": \"./datasets/microagressions/test.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"sbf_test\": {\n","        \"data_path\": \"./datasets/sbf/sbftst.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"dynabench_test\": {\n","        \"data_path\": \"./datasets/dynabench/db_test.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"jigsaw_toxic\": {\n","        \"data_path\": \"./datasets/jigsaw_full_30/test_10k_toxic.txt\",\n","        \"format\": \"txt\",\n","    },\n","    \"paradetox\": {\n","        \"data_path\": \"./datasets/paradetox/test_toxic_parallel.txt\",\n","        \"format\": \"txt\",\n","    },\n","    \"appdia_original\": {\n","        \"data_path\": \"./datasets/appdia/original-annotated-data/original-test.tsv\",\n","        \"format\": \"tsv\",\n","    },\n","    \"appdia_discourse\": {\n","        \"data_path\": \"./datasets/appdia/discourse-augmented-data/discourse-test.tsv\",\n","        \"format\": \"tsv\",\n","    },\n","}\n","\n","# If datasets are in XDetox repo, point to it:\n","DATASET_BASE = \"/content/drive/MyDrive/ds266/w266 - Project/XDetox\"\n","\n","print(f\"✓ {len(data_configs)} test datasets configured:\")\n","for name in data_configs.keys():\n","    print(f\"  - {name}\")"]},{"cell_type":"markdown","metadata":{"id":"l6_6TXaGC5L9"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0S8ot-1C5L9","executionInfo":{"status":"ok","timestamp":1764033503704,"user_tz":480,"elapsed":86,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"2d95782f-d829-4498-c516-f4969949a2aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Helper functions loaded\n"]}],"source":["#@title Helper functions for data loading\n","\n","def _ensure_dir(p):\n","    Path(p).mkdir(parents=True, exist_ok=True)\n","\n","def load_test_data(data_type, num_examples=None):\n","    \"\"\"\n","    Load test data from various formats (.txt, .csv, .tsv).\n","    Returns list of toxic texts as strings.\n","    \"\"\"\n","    if data_type not in data_configs:\n","        raise ValueError(f\"Unknown data_type: {data_type}\")\n","\n","    cfg = data_configs[data_type]\n","    data_path = os.path.join(DATASET_BASE, cfg[\"data_path\"].lstrip(\"./\"))\n","\n","    texts = []\n","\n","    if cfg[\"format\"] == \"txt\":\n","        with open(data_path, 'r', encoding='utf-8') as f:\n","            texts = [line.strip() for line in f if line.strip()]\n","\n","    elif cfg[\"format\"] == \"csv\":\n","        df = pd.read_csv(data_path)\n","        # Try to find the toxic text column\n","        if 'text' in df.columns:\n","            texts = df['text'].tolist()\n","        elif 'toxic' in df.columns:\n","            texts = df['toxic'].tolist()\n","        else:\n","            texts = df.iloc[:, 0].tolist()  # First column\n","\n","    elif cfg[\"format\"] == \"tsv\":\n","        df = pd.read_csv(data_path, sep='\\t')\n","        if 'text' in df.columns:\n","            texts = df['text'].tolist()\n","        else:\n","            texts = df.iloc[:, 0].tolist()\n","\n","    # Clean and convert to strings\n","    cleaned_texts = []\n","    for text in texts:\n","        # Skip NaN, None, or non-string/non-numeric values\n","        if pd.isna(text):\n","            continue\n","        # Convert to string\n","        text_str = str(text).strip()\n","        # Skip empty strings\n","        if text_str:\n","            cleaned_texts.append(text_str)\n","\n","    # Limit to num_examples if specified\n","    if num_examples and num_examples > 0:\n","        cleaned_texts = cleaned_texts[:num_examples]\n","\n","    return cleaned_texts\n","\n","def _safe_float(x):\n","    try:\n","        return float(x)\n","    except Exception:\n","        return float('nan')\n","\n","print(\"✓ Helper functions loaded\")"]},{"cell_type":"markdown","metadata":{"id":"dyHQiqbxC5L_"},"source":["## T5 Model Loading"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlPYvKZgC5L_","executionInfo":{"status":"ok","timestamp":1764033505993,"user_tz":480,"elapsed":2292,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"c525fa69-338b-4b16-a916-8b256cd93800"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading T5 model from /content/drive/MyDrive/ds266/w266 - Project/t5-base-detox-model...\n","✓ T5 model loaded on cpu\n"]}],"source":["#@title Load T5 model\n","print(f\"Loading T5 model from {T5_CHECKPOINT}...\")\n","\n","t5_tokenizer = T5Tokenizer.from_pretrained(T5_CHECKPOINT)\n","t5_model = T5ForConditionalGeneration.from_pretrained(T5_CHECKPOINT)\n","t5_model.eval()\n","\n","# Move to GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","t5_model = t5_model.to(device)\n","\n","print(f\"✓ T5 model loaded on {device}\")"]},{"cell_type":"markdown","metadata":{"id":"WhxGPScEC5MA"},"source":["## T5 Inference Function"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQWFFFZBC5MB","executionInfo":{"status":"ok","timestamp":1764033515558,"user_tz":480,"elapsed":9563,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"7afcab0b-12b3-48f2-b506-a2d6241539c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test: This is a stupid idea\n","Result: This is a bad idea\n"]}],"source":["#@title T5 inference function\n","\n","def t5_detoxify_text(text, model, tokenizer, max_length=128, device=\"cuda\"):\n","    \"\"\"\n","    Generate detoxified text using T5 model.\n","    \"\"\"\n","    input_text = f\"detoxify: {text}\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt', max_length=max_length, truncation=True)\n","    input_ids = input_ids.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_beams=5,\n","            early_stopping=True,\n","            no_repeat_ngram_size=2\n","        )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","def t5_detoxify_batch(texts, model, tokenizer, max_length=128, device=\"cuda\", batch_size=8):\n","    \"\"\"\n","    Batch inference for efficiency.\n","    \"\"\"\n","    results = []\n","\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"T5 Generation\"):\n","        batch = texts[i:i+batch_size]\n","        batch_results = []\n","\n","        for text in batch:\n","            result = t5_detoxify_text(text, model, tokenizer, max_length, device)\n","            batch_results.append(result)\n","\n","        results.extend(batch_results)\n","\n","    return results\n","\n","# Test\n","test_text = \"This is a stupid idea\"\n","detoxified = t5_detoxify_text(test_text, t5_model, t5_tokenizer, device=device)\n","print(f\"Test: {test_text}\")\n","print(f\"Result: {detoxified}\")"]},{"cell_type":"markdown","metadata":{"id":"Bt0wA1kwC5MC"},"source":["## Evaluation Functions"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6tJqcBJC5MC","executionInfo":{"status":"ok","timestamp":1764033527490,"user_tz":480,"elapsed":11934,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"41d99a9d-6dd5-4ced-a27a-ff2746286a3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading evaluation models...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["✓ Evaluation models loaded\n"]}],"source":["#@title Load evaluation models (matching XDetox metrics)\n","\n","print(\"Loading evaluation models...\")\n","\n","# Toxicity classifier\n","tox_tokenizer = AutoTokenizer.from_pretrained(\"s-nlp/roberta_toxicity_classifier\")\n","tox_model = AutoModelForSequenceClassification.from_pretrained(\"s-nlp/roberta_toxicity_classifier\")\n","tox_model.eval()\n","tox_model = tox_model.to(device)\n","\n","# Perplexity model (GPT-2)\n","ppl_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","ppl_model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n","ppl_model.eval()\n","ppl_model = ppl_model.to(device)\n","if ppl_tokenizer.pad_token is None:\n","    ppl_tokenizer.pad_token = ppl_tokenizer.eos_token\n","\n","# Sentence embeddings\n","sim_model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Metrics from evaluate\n","bleu_metric = load(\"sacrebleu\")\n","bertscore_metric = load(\"bertscore\")\n","\n","print(\"✓ Evaluation models loaded\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGjZtWDLC5ME","executionInfo":{"status":"ok","timestamp":1764033527509,"user_tz":480,"elapsed":18,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"95b51c97-0268-4e3b-cddf-e2b3ff1e8d58"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Evaluation functions defined\n"]}],"source":["#@title Evaluation functions\n","\n","def compute_toxicity(texts, tokenizer, model, device=\"cuda\", batch_size=32):\n","    \"\"\"\n","    Compute average toxicity score.\n","    \"\"\"\n","    all_scores = []\n","\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","            toxic_probs = predictions[:, 1]  # Label 1 = toxic\n","            all_scores.extend(toxic_probs.cpu().tolist())\n","\n","    return np.mean(all_scores)\n","\n","def compute_perplexity(texts, tokenizer, model, device=\"cuda\"):\n","    \"\"\"\n","    Compute average perplexity.\n","    \"\"\"\n","    perplexities = []\n","\n","    for text in texts:\n","        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n","            loss = outputs.loss\n","            ppl = torch.exp(loss).item()\n","            perplexities.append(ppl)\n","\n","    return np.mean(perplexities)\n","\n","def compute_bertscore(predictions, references):\n","    \"\"\"\n","    Compute BERTScore.\n","    \"\"\"\n","    result = bertscore_metric.compute(predictions=predictions, references=references, lang=\"en\")\n","    return np.mean(result['f1'])\n","\n","def compute_bleu(predictions, references):\n","    \"\"\"\n","    Compute BLEU score.\n","    \"\"\"\n","    # Format references as list of lists\n","    formatted_refs = [[ref] for ref in references]\n","    result = bleu_metric.compute(predictions=predictions, references=formatted_refs)\n","    return result['score'] / 100.0  # Convert to 0-1 range\n","\n","def evaluate_all(orig_texts, gen_texts, device=\"cuda\"):\n","    \"\"\"\n","    Run all evaluations (matching XDetox metrics).\n","    \"\"\"\n","    results = {}\n","\n","    print(\"  Computing toxicity scores...\")\n","    results['toxicity_gen'] = compute_toxicity(gen_texts, tox_tokenizer, tox_model, device)\n","    results['toxicity_orig'] = compute_toxicity(orig_texts, tox_tokenizer, tox_model, device)\n","\n","    print(\"  Computing perplexity...\")\n","    results['perplexity_gen'] = compute_perplexity(gen_texts, ppl_tokenizer, ppl_model, device)\n","    results['perplexity_orig'] = compute_perplexity(orig_texts, ppl_tokenizer, ppl_model, device)\n","\n","    print(\"  Computing BERTScore...\")\n","    results['bertscore'] = compute_bertscore(gen_texts, orig_texts)\n","\n","    print(\"  Computing BLEU...\")\n","    results['bleu4'] = compute_bleu(gen_texts, orig_texts)\n","\n","    return results\n","\n","print(\"✓ Evaluation functions defined\")"]},{"cell_type":"markdown","metadata":{"id":"ujgMqtl6C5MF"},"source":["## Main Pipeline Function"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08ro8C5iC5MF","executionInfo":{"status":"ok","timestamp":1764033527543,"user_tz":480,"elapsed":21,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"ff309b7b-feb8-481a-ec57-fd406a9de0d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ T5 pipeline function defined\n"]}],"source":["#@title T5 detoxify pipeline (matching XDetox interface)\n","\n","def t5_detoxify_pipeline(\n","    data_type: str = \"paradetox\",\n","    output_folder: str = \"t5_colab_run\",\n","    batch_size: int = 8,\n","    max_length: int = 128,\n","    num_examples: int = 100,\n","    overwrite_gen: bool = False,\n","    run_eval: bool = True,\n","    overwrite_eval: bool = False,\n","):\n","    \"\"\"\n","    Run T5 detoxification pipeline on a dataset.\n","\n","    Mirrors XDetox's detoxify() function interface.\n","    \"\"\"\n","    assert data_type in data_configs, f\"Unknown data_type: {data_type}\"\n","\n","    # Create output directory\n","    base_out_dir = os.path.join(PROJECT_BASE, \"data\", \"t5_outputs\", output_folder)\n","    data_out_dir = os.path.join(base_out_dir, data_type)\n","    _ensure_dir(data_out_dir)\n","\n","    orig_path = os.path.join(data_out_dir, \"orig.txt\")\n","    gen_path = os.path.join(data_out_dir, \"gen.txt\")\n","    stats_path = os.path.join(data_out_dir, \"gen_stats.txt\")\n","\n","    # Generate if needed\n","    if overwrite_gen or not os.path.exists(gen_path):\n","        print(f\"\\n[{data_type}] Loading data...\")\n","        orig_texts = load_test_data(data_type, num_examples)\n","        print(f\"  Loaded {len(orig_texts)} examples\")\n","\n","        print(f\"  Generating detoxified texts...\")\n","        gen_texts = t5_detoxify_batch(\n","            orig_texts,\n","            t5_model,\n","            t5_tokenizer,\n","            max_length=max_length,\n","            device=device,\n","            batch_size=batch_size\n","        )\n","\n","        # Save outputs\n","        with open(orig_path, 'w') as f:\n","            for text in orig_texts:\n","                f.write(text + '\\n')\n","\n","        with open(gen_path, 'w') as f:\n","            for text in gen_texts:\n","                f.write(text + '\\n')\n","\n","        print(f\"  ✓ Saved outputs to {data_out_dir}\")\n","    else:\n","        print(f\"\\n[{data_type}] Loading existing outputs...\")\n","        with open(orig_path, 'r') as f:\n","            orig_texts = [line.strip() for line in f]\n","        with open(gen_path, 'r') as f:\n","            gen_texts = [line.strip() for line in f]\n","        print(f\"  Loaded {len(gen_texts)} examples\")\n","\n","    # Evaluate if needed\n","    if run_eval and (overwrite_eval or not os.path.exists(stats_path)):\n","        print(f\"  Running evaluation...\")\n","        results = evaluate_all(orig_texts, gen_texts, device=device)\n","\n","        # Save stats\n","        with open(stats_path, 'w') as f:\n","            for key, value in results.items():\n","                f.write(f\"{key}: {value}\\n\")\n","\n","        print(f\"  ✓ Saved stats to {stats_path}\")\n","        return results\n","\n","    elif run_eval:\n","        # Load existing stats\n","        print(f\"  Loading existing stats...\")\n","        results = {}\n","        with open(stats_path, 'r') as f:\n","            for line in f:\n","                if ': ' in line:\n","                    key, value = line.strip().split(': ', 1)\n","                    results[key] = _safe_float(value)\n","        return results\n","\n","    return None\n","\n","print(\"✓ T5 pipeline function defined\")"]},{"cell_type":"markdown","metadata":{"id":"ZwSyLnQCC5MG"},"source":["## Run Evaluation on All Datasets"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793,"referenced_widgets":["8479bf0704de4d89a366d42a0eb61226","4b88ef7fa4f24e0082891f409d96f3f1","961a8ceadb574607bb32d21fec97395e","5db4754ae7e04e7e8fc1a89db372156f","d5d00c3d35144beea4167f3ce040f6fb","f0ff5c440606415ca6511e0ae8a50368","f1c77355027c45fc993675c387e8bef3","0ca0fd1034694c9eab474c2504c87d1b","2f67b9dfbe6640579c9a8b64c2313937","9625e9c657fe41eeabfe6577a4692831","ee65d3edf81e46389ad98e07d4a1205b","70632231c4804e9e9fdc124ed79ce946","1fd7a87aa350460a9ade13167518ce2c","8e4495273c3f47eaba4c2c994e91d809","b0e32b4ecf12459686b23e6c69fb50f4","90677cc3d74d4e269b123ca5f959217c","a9520c2872d14019b155508d7e773f2e","ff0835360110459ba6cfb4d013d8dac3","5e0ec6fd86104b17bfeaa5ba910c224c","76911132661e453f93ca1079cb030ee4","3a1c41db19cc448e9cf22c8580c5b32a","8d68133ca41b415390e239aeb71e1da9"]},"id":"oqbPcQgGC5MH","executionInfo":{"status":"ok","timestamp":1764035389281,"user_tz":480,"elapsed":1861736,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"72c28255-3cc2-4fd5-f22b-3ce7d61f8af5"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","T5-PARADETOX PIPELINE\n","================================================================================\n","\n","[paradetox] Loading existing outputs...\n","  Loaded 200 examples\n","  Loading existing stats...\n","  ✓ paradetox complete!\n","\n","[microagressions_test] Loading data...\n","  Loaded 200 examples\n","  Generating detoxified texts...\n"]},{"output_type":"display_data","data":{"text/plain":["T5 Generation:   0%|          | 0/25 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8479bf0704de4d89a366d42a0eb61226"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  ✓ Saved outputs to /content/drive/MyDrive/ds266/w266 - Project/data/t5_outputs/t5_comparison_run/microagressions_test\n","  Running evaluation...\n","  Computing toxicity scores...\n","  Computing perplexity...\n","  Computing BERTScore...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["  Computing BLEU...\n","  ✓ Saved stats to /content/drive/MyDrive/ds266/w266 - Project/data/t5_outputs/t5_comparison_run/microagressions_test/gen_stats.txt\n","  ✓ microagressions_test complete!\n","\n","[sbf_test] Loading data...\n","  Loaded 200 examples\n","  Generating detoxified texts...\n"]},{"output_type":"display_data","data":{"text/plain":["T5 Generation:   0%|          | 0/25 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70632231c4804e9e9fdc124ed79ce946"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  ✓ Saved outputs to /content/drive/MyDrive/ds266/w266 - Project/data/t5_outputs/t5_comparison_run/sbf_test\n","  Running evaluation...\n","  Computing toxicity scores...\n","  Computing perplexity...\n","  Computing BERTScore...\n","  Computing BLEU...\n","  ✓ Saved stats to /content/drive/MyDrive/ds266/w266 - Project/data/t5_outputs/t5_comparison_run/sbf_test/gen_stats.txt\n","  ✓ sbf_test complete!\n","\n","[dynabench_test] Loading existing outputs...\n","  Loaded 200 examples\n","  Loading existing stats...\n","  ✓ dynabench_test complete!\n","\n","================================================================================\n"]}],"source":["#@title Run T5 on multiple datasets\n","\n","# Configuration\n","datasets_to_eval = [\"paradetox\", \"microagressions_test\", \"sbf_test\", \"dynabench_test\"]\n","num_examples = 200  # Match XDetox\n","output_folder = \"t5_comparison_run\"\n","\n","# Store results\n","all_results = {}\n","\n","print(\"=\"*80)\n","print(\"T5-PARADETOX PIPELINE\")\n","print(\"=\"*80)\n","\n","for dataset_name in datasets_to_eval:\n","    try:\n","        results = t5_detoxify_pipeline(\n","            data_type=dataset_name,\n","            output_folder=output_folder,\n","            batch_size=8,\n","            max_length=128,\n","            num_examples=num_examples,\n","            overwrite_gen=False,\n","            run_eval=True,\n","            overwrite_eval=False\n","        )\n","\n","        if results:\n","            all_results[dataset_name] = results\n","            print(f\"  ✓ {dataset_name} complete!\")\n","\n","    except Exception as e:\n","        print(f\"  ✗ Error on {dataset_name}: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        continue\n","\n","print(\"\\n\" + \"=\"*80)"]},{"cell_type":"markdown","metadata":{"id":"wPg4OvwtC5MI"},"source":["## Results Summary"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"An2667zBC5MI","executionInfo":{"status":"ok","timestamp":1764035389313,"user_tz":480,"elapsed":31,"user":{"displayName":"Benjamin Chen He","userId":"13010186992209467638"}},"outputId":"f5be362a-d950-4b72-e461-55d78f0e02d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Saved summary to /content/drive/MyDrive/ds266/w266 - Project/data/t5_outputs/t5_comparison_run/t5_summary.csv\n","\n","================================================================================\n","T5-PARADETOX RESULTS SUMMARY\n","================================================================================\n","             dataset  bertscore    bleu4  perplexity_gen  perplexity_orig  toxicity_gen  toxicity_orig\n","           paradetox   0.952658 0.629718      253.352590       409.280498      0.179528       0.979286\n","microagressions_test   0.981540 0.757424      119.182082       108.895894      0.038149       0.050522\n","            sbf_test   0.997629 0.000000             NaN              NaN      0.000046       0.000045\n","      dynabench_test   0.982489 0.862799      327.626058       312.833179      0.381875       0.499826\n","================================================================================\n"]}],"source":["#@title Display results table (matching XDetox format)\n","\n","if all_results:\n","    # Convert to DataFrame\n","    rows = []\n","    for dataset_name, results in all_results.items():\n","        row = {'dataset': dataset_name}\n","        row.update(results)\n","        rows.append(row)\n","\n","    df = pd.DataFrame(rows)\n","\n","    # Reorder columns to match XDetox\n","    col_order = [\n","        'dataset',\n","        'bertscore',\n","        'bleu4',\n","        'perplexity_gen',\n","        'perplexity_orig',\n","        'toxicity_gen',\n","        'toxicity_orig',\n","    ]\n","    df = df[[col for col in col_order if col in df.columns]]\n","\n","    # Save to CSV\n","    summary_csv = os.path.join(PROJECT_BASE, \"data\", \"t5_outputs\", output_folder, \"t5_summary.csv\")\n","    df.to_csv(summary_csv, index=False)\n","    print(f\"✓ Saved summary to {summary_csv}\\n\")\n","\n","    # Display\n","    print(\"=\"*80)\n","    print(\"T5-PARADETOX RESULTS SUMMARY\")\n","    print(\"=\"*80)\n","    print(df.to_string(index=False))\n","    print(\"=\"*80)\n","else:\n","    print(\"No results available.\")"]},{"cell_type":"markdown","metadata":{"id":"FpiciSnaC5MJ"},"source":["## Comparison Notes\n","\n","This notebook produces results in the same format as XDetox_Pipeline.ipynb:\n","\n","**Metrics (same as XDetox)**:\n","- `bertscore`: Semantic similarity\n","- `bleu4`: N-gram overlap\n","- `perplexity_gen`: Fluency of generated text\n","- `perplexity_orig`: Fluency of original text\n","- `toxicity_gen`: Toxicity of generated text\n","- `toxicity_orig`: Toxicity of original text\n","\n","**Datasets (same as XDetox)**:\n","- paradetox\n","- microagressions_test\n","- sbf_test\n","- dynabench_test\n","- jigsaw_toxic\n","- appdia_original\n","- appdia_discourse\n","\n","**To compare with XDetox**:\n","1. Run XDetox_Pipeline.ipynb with same `num_examples` setting\n","2. Run this notebook with same `num_examples` setting\n","3. Compare the CSV summaries side-by-side\n","4. Lower `toxicity_gen` = better detoxification\n","5. Higher `bertscore` = better meaning preservation\n","6. Lower `perplexity_gen` = more fluent outputs"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.0"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"8479bf0704de4d89a366d42a0eb61226":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b88ef7fa4f24e0082891f409d96f3f1","IPY_MODEL_961a8ceadb574607bb32d21fec97395e","IPY_MODEL_5db4754ae7e04e7e8fc1a89db372156f"],"layout":"IPY_MODEL_d5d00c3d35144beea4167f3ce040f6fb"}},"4b88ef7fa4f24e0082891f409d96f3f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0ff5c440606415ca6511e0ae8a50368","placeholder":"​","style":"IPY_MODEL_f1c77355027c45fc993675c387e8bef3","value":"T5 Generation: 100%"}},"961a8ceadb574607bb32d21fec97395e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ca0fd1034694c9eab474c2504c87d1b","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f67b9dfbe6640579c9a8b64c2313937","value":25}},"5db4754ae7e04e7e8fc1a89db372156f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9625e9c657fe41eeabfe6577a4692831","placeholder":"​","style":"IPY_MODEL_ee65d3edf81e46389ad98e07d4a1205b","value":" 25/25 [16:29&lt;00:00, 38.96s/it]"}},"d5d00c3d35144beea4167f3ce040f6fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ff5c440606415ca6511e0ae8a50368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c77355027c45fc993675c387e8bef3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ca0fd1034694c9eab474c2504c87d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f67b9dfbe6640579c9a8b64c2313937":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9625e9c657fe41eeabfe6577a4692831":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee65d3edf81e46389ad98e07d4a1205b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70632231c4804e9e9fdc124ed79ce946":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fd7a87aa350460a9ade13167518ce2c","IPY_MODEL_8e4495273c3f47eaba4c2c994e91d809","IPY_MODEL_b0e32b4ecf12459686b23e6c69fb50f4"],"layout":"IPY_MODEL_90677cc3d74d4e269b123ca5f959217c"}},"1fd7a87aa350460a9ade13167518ce2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9520c2872d14019b155508d7e773f2e","placeholder":"​","style":"IPY_MODEL_ff0835360110459ba6cfb4d013d8dac3","value":"T5 Generation: 100%"}},"8e4495273c3f47eaba4c2c994e91d809":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e0ec6fd86104b17bfeaa5ba910c224c","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76911132661e453f93ca1079cb030ee4","value":25}},"b0e32b4ecf12459686b23e6c69fb50f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a1c41db19cc448e9cf22c8580c5b32a","placeholder":"​","style":"IPY_MODEL_8d68133ca41b415390e239aeb71e1da9","value":" 25/25 [02:06&lt;00:00,  5.17s/it]"}},"90677cc3d74d4e269b123ca5f959217c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9520c2872d14019b155508d7e773f2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff0835360110459ba6cfb4d013d8dac3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e0ec6fd86104b17bfeaa5ba910c224c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76911132661e453f93ca1079cb030ee4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a1c41db19cc448e9cf22c8580c5b32a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d68133ca41b415390e239aeb71e1da9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}