{"cells":[{"cell_type":"markdown","id":"82d4549b","metadata":{"id":"82d4549b"},"source":["# XDetox Pipeline (DecompX Masking + MaRCo + DecompX Reranking)\n","\n","This notebook runs the original XDetox pipeline, close to `lab.py`, with a few quality-of-life changes:\n","\n","1. **Dataset selector** – choose any dataset from `data_configs`.\n","2. **Small-batch mode** – run only on the first `num_examples` examples.\n","3. **DecompX masking** – token-level toxicity attribution on RoBERTa to decide which tokens to mask with `<mask>`.\n","4. **MaRCo generation** – BART base + non-toxic expert + toxic anti-expert.\n","5. **Optional DecompX-based reranking** – generate several candidates and pick the **least toxic** one.\n","6. **Evaluation** – BLEU, BERTScore, MeaningBERT, perplexity, and toxicity, plus a summary CSV per dataset.\n","\n","---\n","\n","## What this pipeline does\n","\n","For each chosen dataset:\n","\n","1. **Subsetting (optional)**  \n","   - If you set `num_examples`, the script writes a **subset file** under  \n","     `datasets/_subsets/{data_type}/...`  \n","   - This subset matches the format expected by `rewrite.rewrite_example.get_data()`.\n","\n","2. **Masking with DecompX**\n","\n","   - We use a RoBERTa toxicity classifier with DecompX to get **per-token toxicity importance**.\n","   - Tokens that push the prediction towards the toxic class are **replaced with `<mask>`**.\n","   - Masked sentences are saved as:\n","\n","     - `data/model_outputs/{output_folder}/{data_type}/DecompX{thresh}/masked_inputs.txt`\n","\n","   - Thresholds control how aggressively we mask:\n","\n","     - For a threshold value $\\tau$, higher $\\tau$ → **less masking**, lower $\\tau$ → **more masking**.\n","\n","3. **Generation with MaRCo (BART ensemble)**\n","\n","   For each masked input, we use an ensemble of BART models:\n","\n","   - **Base** model (generic BART).\n","   - **Expert** model (trained on non-toxic text).\n","   - **Anti-expert** model (trained on toxic text).\n","\n","   During generation, logits are combined as a **product-of-experts**:\n","\n","   $$\n","   \\text{logits}_{\\text{ens}} = \\alpha_b \\cdot \\text{logits}_{\\text{base}}\n","   + \\alpha_e \\cdot \\text{logits}_{\\text{expert}}\n","   - \\alpha_a \\cdot \\text{logits}_{\\text{anti}}\n","   $$\n","\n","   where:\n","\n","   - $\\alpha_a$ controls how strongly we **push away** from toxic patterns.\n","   - $\\alpha_e$ controls how strongly we **pull towards** non-toxic patterns.\n","   - $\\alpha_b$ controls the influence of the base model.\n","\n","   Sampling is controlled by:\n","\n","   - `sample` (sampling vs greedy),\n","   - `top_k_gen`,\n","   - `top_p`,\n","   - `filter_p`,\n","   - `temperature`,\n","   - `rep_penalty`,\n","   - `max_length`.\n","\n","4. **DecompX-based reranking (inside `rewrite.rewrite_example`)**\n","\n","   When `ranking=True`:\n","\n","   - For each **input sentence**, the generation script samples `num_candidates` candidates.\n","   - For each candidate, it runs the DecompX toxicity model **again** and computes a scalar “toxicity importance” score for that output.\n","   - It then chooses the candidate with **lowest summed toxicity importance** (the “least toxic” according to DecompX).\n","\n","   This happens inside the `rewrite.rewrite_example` module via:\n","\n","   - `--ranking`\n","   - `--ranking_num_output {num_candidates}`\n","\n","5. **Evaluation**\n","\n","   If `run_eval=True`, the notebook calls `evaluation.evaluate_all` for each generation folder and computes:\n","\n","   - BERTScore (F1)\n","   - MeaningBERT\n","   - BLEU-4\n","   - Perplexity (orig / gen)\n","   - Toxicity (orig / gen)\n","   - Optionally percent toxic (if you keep those columns)\n","\n","   For each folder under:\n","\n","   - `data/model_outputs/{output_folder}/{data_type}/DecompX{thresh}/aa*_ae*_.../`\n","\n","   it writes:\n","\n","   - `orig.txt` – original toxic inputs.\n","   - `gen.txt` – final detoxified outputs.\n","   - `gen_stats.txt` – metrics for that run.\n","\n","   Then `_aggregate_eval_csv` aggregates across thresholds into:\n","\n","   - `data/model_outputs/{output_folder}/{data_type}/{data_type}.csv`\n","\n","---\n","\n","## `detoxify()` API\n","\n","Definition:\n","\n","```python\n","def detoxify(\n","    data_type: str = \"paradetox\",\n","    output_folder: str = \"colab_run\",\n","    thresholds = (0.15, 0.20, 0.25),\n","    batch_size: int = 10,\n","    ranking: bool = True,\n","    sample: bool = True,\n","    top_k_gen: int = 50,\n","    top_p: float = 0.95,\n","    filter_p: float = 1.0,\n","    max_length: int = 128,\n","    alpha_a: float = None,\n","    alpha_e: float = None,\n","    alpha_b: float = 1.0,\n","    temperature: float = None,\n","    rep_penalty: float = None,\n","    num_examples: int = 100,\n","    overwrite_gen: bool = False,\n","    run_eval: bool = False,\n","    overwrite_eval: bool = False,\n","    skip_ref_eval: bool = False,\n","    num_candidates: int = 10,\n",")\n","```\n","\n","### Main arguments\n","\n","**Dataset and I/O**\n","\n","* `data_type`\n","  Dataset key from `data_configs`, e.g.:\n","\n","  * `\"paradetox\"`, `\"dynabench_val\"`, `\"jigsaw_toxic\"`, `\"appdia_original\"`, etc.\n","\n","* `output_folder`\n","  Name of the top-level run under `data/dexp_outputs/`.\n","  All outputs for this run go to:\n","\n","  * `data/dexp_outputs/{output_folder}/{data_type}/...`\n","\n","**Masking / thresholds**\n","\n","* `thresholds`\n","  Tuple of DecompX thresholds to try, e.g. `(0.15, 0.20, 0.25)`.\n","  Each threshold ( \\tau ) creates a folder `DecompX{τ}` and its own `masked_inputs.txt`, `orig.txt`, `gen.txt`, etc.\n","\n","* `num_examples`\n","\n","  * If an integer, only the **first N examples** are used (quick debugging).\n","  * If `None`, the full dataset is used.\n","\n","**Generation hyperparameters (MaRCo)**\n","\n","* `sample`\n","\n","  * `True`: use sampling (random but controlled by temperature / top-k / top-p).\n","  * `False`: greedy decoding.\n","\n","* `top_k_gen`\n","  Top-k filter on the **ensembled** logits (only the top-k tokens by probability are kept).\n","\n","* `top_p`\n","  Nucleus (top-p) sampling on the **ensembled** logits. Keeps the smallest set of tokens whose cumulative probability ≥ `top_p`.\n","\n","* `filter_p`\n","  Nucleus filter on the **base model** logits before ensembling (advanced; usually leave at `1.0`).\n","\n","* `max_length`\n","  Maximum length of the generated sequence (in tokens).\n","\n","* `alpha_a`, `alpha_e`, `alpha_b`\n","  Ensemble weights for anti-expert, expert, and base:\n","\n","  * If `None`, defaults from `data_configs[data_type]` are used.\n","\n","* `temperature`\n","  Softens or sharpens the probability distribution:\n","\n","  * Higher temperature → more random.\n","  * Lower temperature → more deterministic.\n","  * If `None`, the dataset default is used.\n","\n","* `rep_penalty`\n","  Repetition penalty (1.0 = no penalty). Larger values discourage repeating tokens.\n","\n","* `batch_size`\n","  Number of sequences to generate in a batch (trade-off between speed and GPU memory).\n","\n","**DecompX reranking**\n","\n","* `ranking`\n","\n","  * `True`: enable DecompX-based reranking of candidates inside `rewrite.rewrite_example`.\n","  * `False`: generate only **one** candidate per input (no reranking).\n","\n","* `num_candidates`\n","\n","  * When `ranking=True`, this sets `--ranking_num_output`.\n","  * For each input, the generator samples `num_candidates` candidates and picks the one with **lowest DecompX toxicity importance**.\n","\n","**Evaluation**\n","\n","* `run_eval`\n","\n","  * If `True`, run `evaluation.evaluate_all` and write `gen_stats.txt` + summary CSV.\n","\n","* `overwrite_gen`\n","\n","  * If `True`, regenerate outputs even if `gen.txt` already exists.\n","\n","* `overwrite_eval`\n","\n","  * If `True`, recompute evaluation values even if `gen_stats.txt` already exists.\n","\n","* `skip_ref_eval`\n","\n","  * If `True`, skip perplexity computation on references (faster).\n","\n","**Echo**\n","* `echo`\n","  * If `True`, print example inputs, masked inputs, generated outputs, and per-threshold evaluation metrics to the notebook.\n","\n","---\n","\n","## Example Usage\n","\n","**Quick test on a subset of ParaDetox (with reranking):**\n","\n","```python\n","detoxify(\n","    data_type=\"paradetox\",\n","    output_folder=\"colab_run_demo\",\n","    thresholds=(0.20,),     # single threshold for quick check\n","    batch_size=8,\n","    ranking=True,           # use DecompX-based reranking\n","    sample=True,\n","    top_k_gen=50,\n","    top_p=0.95,\n","    max_length=96,\n","    num_examples=50,        # use only first 50 examples\n","    run_eval=True,          # compute BLEU / BERTScore / MeaningBERT / PPL / Toxicity\n","    overwrite_gen=True,     # regenerate gen.txt\n","    overwrite_eval=True,    # recompute gen_stats.txt\n","    skip_ref_eval=False,\n","    num_candidates=20,      # 20 candidates per input for DecompX reranking\n",")\n","```\n","\n","**Run without reranking (single candidate per input):**\n","\n","```python\n","detoxify(\n","    data_type=\"paradetox\",\n","    output_folder=\"colab_run_no_rerank\",\n","    thresholds=(0.20,),\n","    batch_size=8,\n","    ranking=False,          # no DecompX reranking\n","    sample=True,\n","    top_k_gen=50,\n","    top_p=0.95,\n","    max_length=96,\n","    num_examples=50,\n","    run_eval=True,\n","    overwrite_gen=True,\n","    overwrite_eval=True,\n","    skip_ref_eval=False,\n",")\n","```\n","\n","After the run, you can inspect:\n","\n","* `orig.txt` / `gen.txt` under `data/model_outputs/{output_folder}/{data_type}/DecompX{thresh}/...`\n","* `gen_stats.txt` for per-run metrics.\n","* `{data_type}.csv` for a summary over thresholds.\n","\n","```\n","::contentReference[oaicite:0]{index=0}\n","```\n"]},{"cell_type":"code","execution_count":null,"id":"h_yizC4pSWVD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32598,"status":"ok","timestamp":1764418790352,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"h_yizC4pSWVD","outputId":"44fc18be-ba34-4adf-d7dd-caabcc4042e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Try MyDrive: /content/drive/MyDrive/w266 - Project/XDetox -> True\n","Using XDETOX_DIR: /content/drive/MyDrive/w266 - Project/XDetox\n"]}],"source":["#@title Mount Drive & locate XDetox\n","from google.colab import drive; drive.mount('/content/drive')\n","import os, glob, re, sys, torch, json, shutil, math, nltk\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from subprocess import run, PIPE\n","\n","# Try My Drive\n","candidate = \"/content/drive/MyDrive/w266 - Project/XDetox\"\n","print(\"Try MyDrive:\", candidate, \"->\", os.path.isdir(candidate))\n","\n","XDETOX_DIR = candidate\n","print(\"Using XDETOX_DIR:\", XDETOX_DIR)\n","assert os.path.isdir(XDETOX_DIR), f\"XDETOX_DIR does not exist: {XDETOX_DIR}\"\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5c1b8054","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1764418790423,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"5c1b8054","outputId":"103af19e-c345-4ec5-f510-2e030bf08e53"},"outputs":[{"name":"stdout","output_type":"stream","text":["XDETOX_DIR: /content/drive/MyDrive/w266 - Project/XDetox\n","TRANSFORMERS_CACHE: /content/drive/MyDrive/w266 - Project/XDetox/cache\n","CUDA available: True\n","GPU: Tesla T4\n"]}],"source":["#@title Runtime setup (paths, cache, GPU)\n","# HuggingFace cache inside the repo (persists on Drive)\n","HF_CACHE = os.path.join(XDETOX_DIR, \"cache\")\n","os.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n","\n","# Add repo to PYTHONPATH\n","if XDETOX_DIR not in sys.path:\n","    sys.path.append(XDETOX_DIR)\n","\n","print(\"XDETOX_DIR:\", XDETOX_DIR)\n","print(\"TRANSFORMERS_CACHE:\", HF_CACHE)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))\n"]},{"cell_type":"code","execution_count":null,"id":"00dd6c0b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1764418790677,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"00dd6c0b","outputId":"f9d5c533-5aa1-4846-8212-907471330c70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Repo folders OK.\n"]}],"source":["#@title Verify XDetox repo layout\n","for d in [\"rewrite\", \"evaluation\", \"datasets\"]:\n","    assert os.path.isdir(os.path.join(XDETOX_DIR, d)), f\"Missing folder: {d}\"\n","print(\"Repo folders OK.\")\n"]},{"cell_type":"code","execution_count":null,"id":"c14a96d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24043,"status":"ok","timestamp":1764418814719,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"c14a96d2","outputId":"2a28410e-d704-4f74-fa8e-d9331eae9cd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#@title Install dependencies (restart runtime if warnings/errors appear)\n","!pip -q install --upgrade pip setuptools wheel\n","!pip -q install \"transformers==4.41.2\" \"tokenizers==0.19.1\" \\\n","                \"datasets==2.19.0\" \"evaluate==0.4.1\" \\\n","                \"sacrebleu==2.4.1\" sacremoses ftfy nltk matplotlib pandas jedi\n","\n","# BERTScore dependency required by evaluate/datasets\n","!pip -q install bert-score"]},{"cell_type":"code","execution_count":null,"id":"f9a132b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1764418815387,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"f9a132b9","outputId":"f67dcfb5-d371-4643-ca9c-dd06dc11815a"},"outputs":[{"name":"stdout","output_type":"stream","text":["NLTK ready\n"]}],"source":["\n","#@title NLTK data\n","nltk.download(\"punkt\", quiet=True)\n","# Some Colab images need this table; ignore if unavailable:\n","try:\n","    nltk.download(\"punkt_tab\", quiet=True)\n","except Exception:\n","    pass\n","print(\"NLTK ready\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0I1tK3vN7i9p","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4312,"status":"ok","timestamp":1764418819702,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"0I1tK3vN7i9p","outputId":"704e331f-1f8a-4e5a-9c85-2e1cbc494fe9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n"]}],"source":["#@title Import from 'rewrite'\n","from rewrite.generation import Infiller\n","from rewrite import rewrite_example as rx\n","import argparse as _argparse"]},{"cell_type":"code","execution_count":null,"id":"8a9c9217","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1764418819726,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"},"user_tz":480},"id":"8a9c9217","outputId":"b3d46dd0-d7e1-455b-9ca8-6e72685cf7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Datasets: microagressions_val, microagressions_test, sbf_val, sbf_test, dynabench_val, dynabench_test, jigsaw_toxic, paradetox, appdia_original, appdia_discourse\n"]}],"source":["\n","#@title Data configs (same as lab.py)\n","data_configs = {\n","    \"microagressions_val\": {\n","        \"data_path\": \"./datasets/microagressions/val.csv\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.25,\n","        \"temperature\": 2.5,\n","    },\n","    \"microagressions_test\": {\n","        \"data_path\": \"./datasets/microagressions/test.csv\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.25,\n","        \"temperature\": 2.5,\n","    },\n","    \"sbf_val\": {\n","        \"data_path\": \"./datasets/sbf/sbfdev.csv\",\n","        \"rep_penalty\": 1.5,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 5.0,\n","        \"temperature\": 2.9,\n","    },\n","    \"sbf_test\": {\n","        \"data_path\": \"./datasets/sbf/sbftst.csv\",\n","        \"rep_penalty\": 1.5,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 5.0,\n","        \"temperature\": 2.9,\n","    },\n","    \"dynabench_val\": {\n","        \"data_path\": \"./datasets/dynabench/db_dev.csv\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.75,\n","        \"temperature\": 2.5,\n","    },\n","    \"dynabench_test\": {\n","        \"data_path\": \"./datasets/dynabench/db_test.csv\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.75,\n","        \"temperature\": 2.5,\n","    },\n","    \"jigsaw_toxic\": {\n","        \"data_path\": \"./datasets/jigsaw_full_30/test_10k_toxic.txt\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.75,\n","        \"temperature\": 2.5,\n","    },\n","    \"paradetox\": {\n","        \"data_path\": \"./datasets/paradetox/test_toxic_parallel.txt\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.75,\n","        \"temperature\": 2.5,\n","    },\n","    \"appdia_original\": {\n","        \"data_path\": \"./datasets/appdia/original-annotated-data/original-test.tsv\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.75,\n","        \"temperature\": 2.5,\n","    },\n","    \"appdia_discourse\": {\n","        \"data_path\": \"./datasets/appdia/discourse-augmented-data/discourse-test.tsv\",\n","        \"rep_penalty\": 1.0,\n","        \"alpha_a\": 1.5,\n","        \"alpha_e\": 4.75,\n","        \"temperature\": 2.5,\n","    }\n","}\n","print(\"Datasets:\", \", \".join(data_configs.keys()))\n"]},{"cell_type":"markdown","id":"52f799fe","metadata":{"id":"52f799fe"},"source":["### Helpers: subset data, call rewrite, run evaluation"]},{"cell_type":"code","execution_count":null,"id":"fcb8508f","metadata":{"id":"fcb8508f"},"outputs":[],"source":["REPO = XDETOX_DIR\n","\n","def _abs_repo_path(rel):\n","    return os.path.join(REPO, rel.lstrip(\"./\"))\n","\n","def _ensure_dir(p):\n","    Path(p).mkdir(parents=True, exist_ok=True)\n","\n","def _subset_for_data_type(data_type, data_path, n, out_dir):\n","    \"\"\"Create a small subset file matching the expected format used by rewrite_example.get_data().\n","    Returns the path to the *new* subset file (or original path if n is None).\n","    \"\"\"\n","    if n is None or n <= 0:\n","        return data_path  # no subset\n","\n","    src = _abs_repo_path(data_path)\n","    _ensure_dir(out_dir)\n","\n","    if \"microagressions\" in data_path:\n","        df = pd.read_csv(src)\n","        cols = df.columns.tolist()\n","        sub = df.head(n)\n","        out = os.path.join(out_dir, os.path.basename(src))\n","        sub.to_csv(out, index=False)\n","        return out\n","\n","    if \"sbf\" in data_path:\n","        df = pd.read_csv(src)\n","        sub = df.head(n)\n","        out = os.path.join(out_dir, os.path.basename(src))\n","        sub.to_csv(out, index=False)\n","        return out\n","\n","    if \"dynabench\" in data_path:\n","        df = pd.read_csv(src)\n","        sub = df.head(n)\n","        out = os.path.join(out_dir, os.path.basename(src))\n","        sub.to_csv(out, index=False)\n","        return out\n","\n","    if any(k in data_path for k in [\"paradetox\", \"jigsaw\"]):\n","        # txt file\n","        if data_path.endswith(\".txt\"):\n","            with open(src, \"r\") as f:\n","                lines = [s.rstrip(\"\\n\") for s in f.readlines()]\n","            out = os.path.join(out_dir, os.path.basename(src))\n","            with open(out, \"w\") as g:\n","                for s in lines[:n]:\n","                    g.write(s + \"\\n\")\n","            return out\n","        elif data_path.endswith(\".csv\"):\n","            df = pd.read_csv(src).head(n)\n","            out = os.path.join(out_dir, os.path.basename(src))\n","            df.to_csv(out, index=False)\n","            return out\n","\n","    if \"appdia\" in data_path:\n","        # tsv\n","        df = pd.read_csv(src, sep=\"\\t\").head(n)\n","        out = os.path.join(out_dir, os.path.basename(src))\n","        df.to_csv(out, sep=\"\\t\", index=False)\n","        return out\n","\n","    # Fallback: copy original\n","    out = os.path.join(out_dir, os.path.basename(src))\n","    shutil.copy(src, out)\n","    return out\n","\n","def _parse_run_folder_name(folder_name):\n","    pattern = r\"aa(\\d+\\.\\d+)_ae(\\d+\\.\\d+)_ab(\\d+\\.\\d+)_base(.*?)_anti(.*?)_expert(.*?)_temp(\\d+\\.\\d+)_sample(.*?)_topk(\\d+)_reppenalty(\\d+\\.\\d+)_filterp(\\d+\\.\\d+)_maxlength(\\d+)_topp(\\d+\\.\\d+)\"\n","    m = re.match(pattern, folder_name)\n","    return bool(m)\n","\n","def _eval_with_toxicity(base_path, overwrite_eval=False, skip_ref=False, tox_threshold=0.5, tox_batch_size=32):\n","    import sys, os\n","    for folder in os.listdir(base_path):\n","        gen_dir = os.path.join(base_path, folder)\n","        if not os.path.isdir(gen_dir) or not _parse_run_folder_name(folder):\n","            continue\n","        orig_path = os.path.join(gen_dir, \"orig.txt\")\n","        gen_path  = os.path.join(gen_dir, \"gen.txt\")\n","        out_stats = os.path.join(gen_dir, \"gen_stats.txt\")  # note: now _stats.txt\n","        if not (os.path.exists(orig_path) and os.path.exists(gen_path)):\n","            continue\n","        if os.path.exists(out_stats) and not overwrite_eval:\n","            continue\n","\n","        env = os.environ.copy()\n","        env[\"PYTHONPATH\"] = REPO + (\":\" + env.get(\"PYTHONPATH\",\"\") if env.get(\"PYTHONPATH\") else \"\")\n","        cmd = [\n","            sys.executable, \"-m\", \"evaluation.evaluate_all\",\n","            \"--orig_path\", orig_path,\n","            \"--gen_path\",  gen_path,\n","            \"--tox_threshold\", str(tox_threshold),\n","            \"--tox_batch_size\", str(tox_batch_size),\n","        ]\n","        if skip_ref:\n","            cmd.append(\"--skip_ref\")\n","        print(\"Eval:\", \" \".join(cmd))\n","        res = run(cmd, cwd=REPO, env=env, stdout=PIPE, stderr=PIPE, text=True)\n","        if res.returncode != 0:\n","            print(res.stdout)\n","            print(res.stderr)\n","            res.check_returncode()\n","\n","\n","def _safe_float(x):\n","    try:\n","        return float(x)\n","    except Exception:\n","        return float('nan')\n","\n","def _read_stats_file(path):\n","    \"\"\"Read gen_stats_notox.txt into a dict of floats; tolerate '(skipped): None'.\"\"\"\n","    out = {}\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            if \":\" not in line:\n","                continue\n","            k, v = line.strip().split(\": \", 1)\n","            # normalize keys like 'perplexity orig (skipped)' -> 'perplexity orig'\n","            k = k.replace(\"(skipped)\", \"\").strip().lower()\n","            out[k] = _safe_float(v)\n","    return out\n","\n","def _aggregate_eval_csv(output_folder, data_type, base_out_dir):\n","    rows = []\n","    for thresh in np.arange(0.15, 0.3, 0.05, dtype=np.float64):\n","        mask_dir = f\"DecompX{abs(thresh):g}\" if thresh != 0 else \"DecompX0.0\"\n","        base_path = os.path.join(base_out_dir, data_type, mask_dir)\n","        if not os.path.isdir(base_path):\n","            continue\n","        for folder in os.listdir(base_path):\n","            gen_dir = os.path.join(base_path, folder)\n","            stats_path = os.path.join(gen_dir, \"gen_stats.txt\")\n","            if not os.path.exists(stats_path):\n","                continue\n","            s = _read_stats_file(stats_path)\n","            rows.append({\n","                \"threshold\":        float(f\"{thresh:.2f}\"),\n","                \"folder\":           folder,\n","                \"bertscore\":        s.get(\"bertscore\", np.nan),\n","                \"meaningbert\":      s.get(\"meaningbert\", np.nan),   # NEW\n","                \"bleu4\":            s.get(\"bleu4\", np.nan),\n","                \"perplexity_gen\":   s.get(\"perplexity gen\", np.nan),\n","                \"perplexity_orig\":  s.get(\"perplexity orig\", np.nan),\n","                \"toxicity_gen\":     s.get(\"toxicity gen\", np.nan),\n","                \"toxicity_orig\":    s.get(\"toxicity orig\", np.nan),\n","                # Optional: you can also keep the percent toxic columns\n","                # \"percent_toxic_gen\": s.get(\"percent toxic gen\", np.nan),\n","                # \"percent_toxic_ref\": s.get(\"percent toxic ref\", np.nan),\n","            })\n","\n","    if rows:\n","        # Column order: MeaningBERT between BERTScore and BLEU4\n","        cols = [\n","            \"threshold\", \"folder\",\n","            \"bertscore\", \"meaningbert\", \"bleu4\",\n","            \"perplexity_gen\", \"perplexity_orig\",\n","            \"toxicity_gen\", \"toxicity_orig\",\n","            # \"percent_toxic_gen\", \"percent_toxic_ref\",\n","        ]\n","        df = pd.DataFrame(rows)\n","        df = df[cols]\n","        out_csv = os.path.join(base_out_dir, data_type, f\"{data_type}.csv\")\n","        df.to_csv(out_csv, index=False)\n","        print(\"Wrote summary CSV:\", out_csv)\n","    else:\n","        print(\"No evaluation files found to summarize.\")\n","def _bool2str(x: bool) -> str:\n","    return \"T\" if x else \"F\"\n","\n","\n","def _build_gen_folder_name(\n","    alpha_a, alpha_e, alpha_b,\n","    base_type, antiexpert_type, expert_type,\n","    temperature, sample, top_k_gen, rep_penalty, filter_p, max_length, top_p\n","):\n","    \"\"\"\n","    Rebuild the run folder name used by rewrite.rewrite_example so we can\n","    locate gen.txt / orig.txt / gen_stats.txt for echo and evaluation.\n","    \"\"\"\n","    return (\n","        \"aa\" + str(alpha_a) +\n","        \"_ae\" + str(alpha_e) +\n","        \"_ab\" + str(alpha_b) +\n","        \"_base\" + base_type[:5] +\n","        \"_anti\" + antiexpert_type[:5] +\n","        \"_expert\" + expert_type[:5] +\n","        \"_temp\" + str(temperature) +\n","        \"_sample\" + _bool2str(sample) +\n","        \"_topk\" + str(top_k_gen) +\n","        \"_reppenalty\" + str(rep_penalty) +\n","        \"_filterp\" + str(filter_p) +\n","        \"_maxlength\" + str(max_length) +\n","        \"_topp\" + str(top_p)\n","    )\n"]},{"cell_type":"code","execution_count":null,"id":"92b940a3","metadata":{"id":"92b940a3"},"outputs":[],"source":["#@title `detoxify()` — run masking + generation + optional eval\n","\n","def detoxify(\n","    data_type: str = \"paradetox\",\n","    output_folder: str = \"colab_run\",\n","    thresholds = (0.15, 0.20, 0.25),\n","    echo: bool = False,             # NEW\n","    batch_size: int = 10,\n","    ranking: bool = True,\n","    sample: bool = True,\n","    top_k_gen: int = 50,\n","    top_p: float = 0.95,\n","    filter_p: float = 1.0,\n","    max_length: int = 128,\n","    alpha_a: float = None,   # if None, take from data_configs\n","    alpha_e: float = None,   # if None, take from data_configs\n","    alpha_b: float = 1.0,\n","    temperature: float = None,  # if None, from data_configs\n","    rep_penalty: float = None,  # if None, from data_configs\n","    num_examples: int = 100,    # small-batch control; set None to use full dataset\n","    overwrite_gen: bool = False,\n","    run_eval: bool = False,\n","    overwrite_eval: bool = False,\n","    skip_ref_eval: bool = False,\n","    # number of candidates per input for DecompX reranking\n","    num_candidates: int = 10,\n","):\n","    \"\"\"\n","    Run the XDetox pipeline similarly to lab.py but with small-batch support,\n","    optional DecompX-based reranking, and evaluation including\n","    BLEU, BERTScore, MeaningBERT, perplexity, and toxicity.\n","\n","    When `ranking=True`, `num_candidates` controls how many candidates per\n","    input DecompX generates and reranks (via --ranking_num_output).\n","\n","    If echo=True, the function will print:\n","      - how many examples and which dataset,\n","      - a few example inputs,\n","      - a few masked inputs (per threshold),\n","      - a few detoxified outputs (per threshold),\n","      - evaluation metrics (per threshold) from gen_stats.txt (if run_eval=True).\n","    \"\"\"\n","\n","    assert data_type in data_configs, f\"Unknown data_type: {data_type}\"\n","    cfg = data_configs[data_type].copy()\n","\n","    if ranking and num_candidates < 1:\n","        raise ValueError(\"num_candidates must be >= 1 when ranking=True\")\n","\n","    # fallbacks from data_configs\n","    if alpha_a is None:\n","        alpha_a = cfg[\"alpha_a\"]\n","    if alpha_e is None:\n","        alpha_e = cfg[\"alpha_e\"]\n","    if temperature is None:\n","        temperature = cfg[\"temperature\"]\n","    if rep_penalty is None:\n","        rep_penalty = cfg[\"rep_penalty\"]\n","\n","    # Use model_outputs instead of dexp_outputs\n","    base_out_dir = os.path.join(\"data\", \"model_outputs\", output_folder)\n","    abs_base_out_dir = os.path.join(REPO, base_out_dir)\n","    _ensure_dir(abs_base_out_dir)\n","\n","    # small subset path creation\n","    original_data_path = cfg[\"data_path\"]\n","    subset_dir = os.path.join(REPO, \"datasets\", \"_subsets\", data_type)\n","    _ensure_dir(subset_dir)\n","    subset_path = _subset_for_data_type(\n","        data_type, original_data_path, num_examples, subset_dir\n","    )\n","\n","    # Load inputs once (same logic as rewrite_example.get_data) for echo\n","    args_data = _argparse.Namespace(data_type=data_type, data_path=subset_path)\n","    inputs = rx.get_data(args_data)\n","    num_inputs = len(inputs)\n","\n","    if echo:\n","        print(\"=\" * 80)\n","        print(f\"[echo] Dataset: {data_type}\")\n","        print(f\"[echo] Subset path: {subset_path}\")\n","        print(f\"[echo] Output base: {abs_base_out_dir}\")\n","        print(f\"[echo] Number of examples to detoxify: {num_inputs}\")\n","        print(f\"[echo] Thresholds: {', '.join(f'{t:.2f}' for t in thresholds)}\")\n","        print(f\"[echo] ranking: {ranking}, num_candidates: {num_candidates}\")\n","        print(\"\\n[echo] Example inputs (first up to 3):\")\n","        for i, s in enumerate(inputs[:3]):\n","            print(f\"  input[{i}]: {s}\")\n","        print(\"=\" * 80)\n","\n","    # These are the fixed types used by the MaRCo models\n","    base_type = \"base\"\n","    antiexpert_type = \"antiexpert\"\n","    expert_type = \"expert\"\n","\n","    # Folder name used by rewrite_example for this set of hyperparameters\n","    gen_folder = _build_gen_folder_name(\n","        alpha_a, alpha_e, alpha_b,\n","        base_type, antiexpert_type, expert_type,\n","        temperature, sample, top_k_gen, rep_penalty, filter_p, max_length, top_p\n","    )\n","\n","    # run thresholds\n","    for t in thresholds:\n","        mask_dir = f\"DecompX{abs(t):g}\" if t != 0 else \"DecompX0.0\"\n","        thresh_root_dir = os.path.join(abs_base_out_dir, data_type, mask_dir)\n","        _ensure_dir(thresh_root_dir)\n","\n","        # Build command to call rewrite module\n","        cmd = [\n","            sys.executable, \"-m\", \"rewrite.rewrite_example\",\n","            \"--output_dir\", base_out_dir,           # relative to REPO\n","            \"--data_type\", data_type,\n","            \"--data_path\", subset_path.replace(REPO + \"/\", \"./\"),\n","            \"--rep_penalty\", str(rep_penalty),\n","            \"--alpha_a\", str(alpha_a),\n","            \"--alpha_e\", str(alpha_e),\n","            \"--temperature\", str(temperature),\n","            \"--alpha_b\", str(alpha_b),\n","            \"--max_length\", str(max_length),\n","            \"--batch_size\", str(batch_size),\n","            \"--top_k_gen\", str(top_k_gen),\n","            \"--top_p\", str(top_p),\n","            \"--filter_p\", str(filter_p),\n","            \"--thresh\", f\"{t:.2f}\",\n","        ]\n","\n","        # DecompX reranking: pass both the flag and the number of candidates\n","        if ranking:\n","            cmd.append(\"--ranking\")\n","            cmd.extend([\"--ranking_num_output\", str(num_candidates)])\n","\n","        if sample:\n","            cmd.append(\"--sample\")\n","        if overwrite_gen:\n","            cmd.append(\"--overwrite_gen\")\n","\n","        print(\"Run:\", \" \".join(cmd))\n","        run(cmd, cwd=REPO, check=True)\n","\n","        # ------------------------------------------------------------------\n","        # echo: show masked inputs and detoxified outputs for this threshold\n","        # ------------------------------------------------------------------\n","        if echo:\n","            print(\"\\n\" + \"-\" * 80)\n","            print(f\"[echo] Threshold t={t:.2f} — sample masked and generated outputs\")\n","\n","            # masked inputs (one file per threshold)\n","            masked_path = os.path.join(thresh_root_dir, \"masked_inputs.txt\")\n","            if os.path.exists(masked_path):\n","                with open(masked_path, \"r\") as f:\n","                    masked_lines = [l.strip() for l in f.readlines()]\n","                print(\"[echo] Example masked inputs (first up to 3):\")\n","                for i, m in enumerate(masked_lines[:3]):\n","                    print(f\"  masked[{i}]: {m}\")\n","            else:\n","                print(f\"[echo] masked_inputs.txt not found at {masked_path}\")\n","\n","            # generated detoxified outputs for this hyperparameter setting\n","            run_dir = os.path.join(thresh_root_dir, gen_folder)\n","            gen_txt = os.path.join(run_dir, \"gen.txt\")\n","            if os.path.exists(gen_txt):\n","                with open(gen_txt, \"r\") as f:\n","                    gen_lines = [l.strip() for l in f.readlines()]\n","                print(\"\\n[echo] Example detoxified outputs (first up to 3):\")\n","                for i, g in enumerate(gen_lines[:3]):\n","                    print(f\"  detox[{i}]: {g}\")\n","            else:\n","                print(f\"[echo] gen.txt not found at {gen_txt}\")\n","\n","        # Optional evaluation (BLEU / BERTScore / MeaningBERT / PPL / Toxicity)\n","        if run_eval:\n","            base_path = os.path.join(abs_base_out_dir, data_type, mask_dir)\n","            _eval_with_toxicity(\n","                base_path,\n","                overwrite_eval=overwrite_eval,\n","                skip_ref=skip_ref_eval,\n","                tox_threshold=0.5,\n","                tox_batch_size=32,\n","            )\n","\n","            # echo: print metrics for THIS run (this threshold + this gen folder)\n","            if echo:\n","                stats_path = os.path.join(base_path, gen_folder, \"gen_stats.txt\")\n","                if os.path.exists(stats_path):\n","                    stats = _read_stats_file(stats_path)\n","                    print(\"\\n[echo] Evaluation metrics for this run \"\n","                          f\"(t={t:.2f}):\")\n","                    metric_keys = [\n","                        (\"bertscore\", \"BERTScore\"),\n","                        (\"meaningbert\", \"MeaningBERT\"),\n","                        (\"bleu4\", \"BLEU-4\"),\n","                        (\"perplexity gen\", \"Perplexity (gen)\"),\n","                        (\"perplexity orig\", \"Perplexity (orig)\"),\n","                        (\"toxicity gen\", \"Toxicity (gen)\"),\n","                        (\"toxicity orig\", \"Toxicity (orig)\"),\n","                    ]\n","                    for key, label in metric_keys:\n","                        val = stats.get(key, None)\n","                        if isinstance(val, float) and math.isnan(val):\n","                            continue\n","                        if val is None:\n","                            continue\n","                        print(f\"  {label}: {val:.4f}\")\n","                else:\n","                    print(f\"[echo] gen_stats.txt not found at {stats_path}\")\n","\n","    # Summarize metrics across thresholds into a CSV\n","    if run_eval:\n","        _aggregate_eval_csv(\n","            output_folder,\n","            data_type,\n","            os.path.join(REPO, \"data\", \"model_outputs\", output_folder),\n","        )\n"]},{"cell_type":"markdown","id":"72e393cd","metadata":{"id":"72e393cd"},"source":["### Example run"]},{"cell_type":"code","execution_count":null,"id":"2b7626ce","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2b7626ce","outputId":"5af989a5-4e70-4f7d-e01b-d9a93a26712a"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","[echo] Dataset: paradetox\n","[echo] Subset path: /content/drive/MyDrive/w266 - Project/XDetox/datasets/_subsets/paradetox/test_toxic_parallel.txt\n","[echo] Output base: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/XDetox_w_DecompX-Masking-DecompX-Reranking\n","[echo] Number of examples to detoxify: 671\n","[echo] Thresholds: 0.20\n","[echo] ranking: True, num_candidates: 10\n","\n","[echo] Example inputs (first up to 3):\n","  input[0]: . or the loud ass one - thousand ton beast roaring towards you howling its horn .\n","  input[1]: mandated  and \" right fucking now \" would be good .\n","  input[2]: * neither * of my coworkers gave a shit when it came time to ditch mitch . ugh .\n","================================================================================\n","Run: /usr/bin/python3 -m rewrite.rewrite_example --output_dir data/model_outputs/XDetox_w_DecompX-Masking-DecompX-Reranking --data_type paradetox --data_path ./datasets/_subsets/paradetox/test_toxic_parallel.txt --rep_penalty 1.0 --alpha_a 1.5 --alpha_e 4.75 --temperature 2.5 --alpha_b 1.0 --max_length 96 --batch_size 8 --top_k_gen 50 --top_p 0.95 --filter_p 1.0 --thresh 0.20 --ranking --ranking_num_output 10 --sample --overwrite_gen\n"]},{"ename":"CalledProcessError","evalue":"Command '['/usr/bin/python3', '-m', 'rewrite.rewrite_example', '--output_dir', 'data/model_outputs/XDetox_w_DecompX-Masking-DecompX-Reranking', '--data_type', 'paradetox', '--data_path', './datasets/_subsets/paradetox/test_toxic_parallel.txt', '--rep_penalty', '1.0', '--alpha_a', '1.5', '--alpha_e', '4.75', '--temperature', '2.5', '--alpha_b', '1.0', '--max_length', '96', '--batch_size', '8', '--top_k_gen', '50', '--top_p', '0.95', '--filter_p', '1.0', '--thresh', '0.20', '--ranking', '--ranking_num_output', '10', '--sample', '--overwrite_gen']' returned non-zero exit status 1.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3111774425.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m detoxify(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"paradetox\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"XDetox_w_DecompX-Masking-DecompX-Reranking\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mecho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3516650440.py\u001b[0m in \u001b[0;36mdetoxify\u001b[0;34m(data_type, output_folder, thresholds, echo, batch_size, ranking, sample, top_k_gen, top_p, filter_p, max_length, alpha_a, alpha_e, alpha_b, temperature, rep_penalty, num_examples, overwrite_gen, run_eval, overwrite_eval, skip_ref_eval, num_candidates)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# ------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '['/usr/bin/python3', '-m', 'rewrite.rewrite_example', '--output_dir', 'data/model_outputs/XDetox_w_DecompX-Masking-DecompX-Reranking', '--data_type', 'paradetox', '--data_path', './datasets/_subsets/paradetox/test_toxic_parallel.txt', '--rep_penalty', '1.0', '--alpha_a', '1.5', '--alpha_e', '4.75', '--temperature', '2.5', '--alpha_b', '1.0', '--max_length', '96', '--batch_size', '8', '--top_k_gen', '50', '--top_p', '0.95', '--filter_p', '1.0', '--thresh', '0.20', '--ranking', '--ranking_num_output', '10', '--sample', '--overwrite_gen']' returned non-zero exit status 1."]}],"source":["\n","detoxify(\n","    data_type=\"paradetox\",\n","    output_folder=\"XDetox_w_DecompX-Masking-DecompX-Reranking\",\n","    thresholds=(0.20,),\n","    echo=True,\n","    batch_size=8,\n","    ranking=True,\n","    sample=True,\n","    top_k_gen=50,\n","    top_p=0.95,\n","    max_length=96,\n","    num_examples=1000,\n","    run_eval=True,\n","    overwrite_gen=True,\n","    overwrite_eval=True,\n","    skip_ref_eval=False,\n","    num_candidates=10,\n",")\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}