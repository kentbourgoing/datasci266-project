{"cells":[{"cell_type":"markdown","metadata":{"id":"RMv0Aj_pDqs_"},"source":["# T5-ParaDetox Pipeline with Global Reranking\n","\n","This notebook combines:\n","- **T5-base** fine-tuned on ParaDetox for detoxification\n","- **Global reranking** using toxicity, semantic similarity, and fluency\n","\n","## Pipeline\n","\n","1. Generate `num_candidates` detoxified texts per input using T5 sampling\n","2. Score each candidate using:\n","   - **Toxicity** (XLM-R large classifier)\n","   - **Semantic Similarity** (LaBSE embeddings)\n","   - **Fluency** (GPT-2 perplexity)\n","3. Select candidate with highest weighted score\n","4. Evaluate with BLEU, BERTScore, MeaningBERT, Perplexity, Toxicity\n","\n","---\n","\n","## Global Reranking Formula\n","\n","For each candidate $c$:\n","\n","$$\\text{Score}(c) = w_T \\cdot (1 - \\text{Toxicity}(c)) + w_S \\cdot \\text{Similarity}(c) + w_F \\cdot \\text{Fluency}(c)$$\n","\n","Default weights: $(w_T, w_S, w_F) = (0.5, 0.3, 0.2)$\n","\n","---\n","\n","## `detoxify()` API\n","\n","```python\n","def detoxify(\n","    data_type: str = \"paradetox\",\n","    output_folder: str = \"T5_w_Global-Reranking\",\n","    batch_size: int = 8,\n","    max_length: int = 128,\n","    num_examples: int = 100,\n","    num_candidates: int = 10,\n","    temperature: float = 1.0,\n","    top_k: int = 50,\n","    top_p: float = 0.95,\n","    weights: tuple = (0.5, 0.3, 0.2),  # (toxicity, similarity, fluency)\n","    overwrite_gen: bool = False,\n","    run_eval: bool = True,\n","    overwrite_eval: bool = False,\n","    echo: bool = False,\n",")\n","```\n","\n","### Key Arguments\n","\n","- `data_type`: Dataset key (paradetox, microagressions_test, sbf_test, dynabench_test, jigsaw_toxic, appdia_original, appdia_discourse)\n","- `output_folder`: Folder under `data/model_outputs/` for results\n","- `num_candidates`: Number of candidates to generate per input for reranking\n","- `weights`: Tuple of (toxicity_weight, similarity_weight, fluency_weight)\n","- `echo`: If True, print example inputs, candidates, and outputs"]},{"cell_type":"markdown","metadata":{"id":"543x6Fy0DqtB"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ud3c2kUaDqtB","executionInfo":{"status":"ok","timestamp":1764841696418,"user_tz":480,"elapsed":36555,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"7de994ba-6782-4ce8-fae9-d00312ad3f61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","PROJECT_BASE: /content/drive/MyDrive/w266 - Project\n","XDETOX_DIR: /content/drive/MyDrive/w266 - Project/XDetox\n","T5_CHECKPOINT: /content/drive/MyDrive/w266 - Project/t5-base-detox-model\n","XDETOX exists: True\n","T5 checkpoint exists: True\n"]}],"source":["#@title Mount Drive & locate project\n","from google.colab import drive; drive.mount('/content/drive')\n","\n","import os, sys, torch\n","\n","# Adjust this if your project lives somewhere else\n","PROJECT_BASE = \"/content/drive/MyDrive/w266 - Project\"\n","XDETOX_DIR   = os.path.join(PROJECT_BASE, \"XDetox\")\n","T5_CHECKPOINT = os.path.join(PROJECT_BASE, \"t5-base-detox-model\")\n","\n","if XDETOX_DIR not in sys.path:\n","    sys.path.append(XDETOX_DIR)\n","\n","print(\"PROJECT_BASE:\", PROJECT_BASE)\n","print(\"XDETOX_DIR:\", XDETOX_DIR)\n","print(\"T5_CHECKPOINT:\", T5_CHECKPOINT)\n","print(\"XDETOX exists:\", os.path.isdir(XDETOX_DIR))\n","print(\"T5 checkpoint exists:\", os.path.isdir(T5_CHECKPOINT) or os.path.isfile(T5_CHECKPOINT))\n","\n","assert os.path.isdir(XDETOX_DIR), f\"XDETOX_DIR does not exist: {XDETOX_DIR}\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fymNrn7hDqtC","executionInfo":{"status":"ok","timestamp":1764841697267,"user_tz":480,"elapsed":841,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"08591b82-4c17-42ba-8fce-b8d50603a81d"},"outputs":[{"output_type":"stream","name":"stdout","text":["TRANSFORMERS_CACHE: /content/drive/MyDrive/w266 - Project/XDetox/cache\n","CUDA available: True\n","GPU: Tesla T4\n"]}],"source":["#@title Runtime setup (cache, GPU)\n","HF_CACHE = os.path.join(XDETOX_DIR, \"cache\")\n","os.makedirs(HF_CACHE, exist_ok=True)\n","os.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","print(\"TRANSFORMERS_CACHE:\", HF_CACHE)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kuBYmJ7ODqtC","executionInfo":{"status":"ok","timestamp":1764841697289,"user_tz":480,"elapsed":10,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"27aa4ca6-3cc7-42ae-96f1-1cd804b14d8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Repo folders OK.\n"]}],"source":["#@title Verify XDetox repo layout\n","for d in [\"rewrite\", \"evaluation\", \"datasets\", \"data\"]:\n","    assert os.path.isdir(os.path.join(XDETOX_DIR, d)), f\"Missing folder: {d}\"\n","print(\"Repo folders OK.\")"]},{"cell_type":"code","source":["#@title Install dependencies (aligned with LLM pipeline)\n","!pip -q install --upgrade pip setuptools wheel\n","!pip -q install \"transformers==4.41.2\" \"tokenizers==0.19.1\" \\\n","                \"datasets==2.19.0\" \"evaluate==0.4.1\" \\\n","                \"sacrebleu==2.4.1\" sacremoses ftfy nltk matplotlib pandas jedi \\\n","                sentencepiece\n","!pip -q install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNpMaOVhvOjQ","executionInfo":{"status":"ok","timestamp":1764841722602,"user_tz":480,"elapsed":25310,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"3910f321-471e-47a2-fa6b-fd4680fef39a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.8 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtIkjDQlDqtC","executionInfo":{"status":"ok","timestamp":1764841730737,"user_tz":480,"elapsed":8120,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"4b0ca2a3-1973-4b7d-9a7d-bf296f88da1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["NLTK ready\n"]}],"source":["#@title NLTK data\n","import nltk\n","nltk.download(\"punkt\", quiet=True)\n","try:\n","    nltk.download(\"punkt_tab\", quiet=True)\n","except Exception:\n","    pass\n","print(\"NLTK ready\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGpelOH9DqtC","executionInfo":{"status":"ok","timestamp":1764841733005,"user_tz":480,"elapsed":2254,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"a972267e-a3e2-485b-8cea-76476fc0f45e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Libraries imported\n"]}],"source":["#@title Imports\n","import glob, re, json, shutil, math\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from subprocess import run, PIPE\n","from typing import List, Tuple\n","\n","from transformers import (\n","    T5Tokenizer, T5ForConditionalGeneration,\n","    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n","    GPT2TokenizerFast, GPT2LMHeadModel,\n",")\n","print(\"Libraries imported\")\n","\n","REPO = XDETOX_DIR"]},{"cell_type":"markdown","metadata":{"id":"ru-0RPVZDqtC"},"source":["## Dataset Configuration"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XQpJjq5DqtC","executionInfo":{"status":"ok","timestamp":1764841733015,"user_tz":480,"elapsed":6,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"d2e003d6-9b40-4990-b7a8-530cd63b629e"},"outputs":[{"output_type":"stream","name":"stdout","text":["7 datasets configured: paradetox, microagressions_test, sbf_test, dynabench_test, jigsaw_toxic, appdia_original, appdia_discourse\n"]}],"source":["#@title Data configs (matching XDetox paths + formats)\n","data_configs = {\n","    \"paradetox\": {\n","        \"data_path\": \"./datasets/paradetox/test_toxic_parallel.txt\",\n","        \"format\": \"txt\",\n","    },\n","    \"microagressions_test\": {\n","        \"data_path\": \"./datasets/microagressions/test.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"sbf_test\": {\n","        \"data_path\": \"./datasets/sbf/sbftst.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"dynabench_test\": {\n","        \"data_path\": \"./datasets/dynabench/db_test.csv\",\n","        \"format\": \"csv\",\n","    },\n","    \"jigsaw_toxic\": {\n","        \"data_path\": \"./datasets/jigsaw_full_30/test_10k_toxic.txt\",\n","        \"format\": \"txt\",\n","    },\n","    \"appdia_original\": {\n","        \"data_path\": \"./datasets/appdia/original-annotated-data/original-test.tsv\",\n","        \"format\": \"tsv\",\n","    },\n","    \"appdia_discourse\": {\n","        \"data_path\": \"./datasets/appdia/discourse-augmented-data/discourse-test.tsv\",\n","        \"format\": \"tsv\",\n","    },\n","}\n","print(f\"{len(data_configs)} datasets configured:\", \", \".join(data_configs.keys()))"]},{"cell_type":"markdown","metadata":{"id":"fL2mQjuKDqtC"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Dc1YKaJDqtD","executionInfo":{"status":"ok","timestamp":1764841733043,"user_tz":480,"elapsed":25,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"c416d839-f086-4030-a6ca-3cbd6410118e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Helper functions loaded\n"]}],"source":["#@title Helper functions (I/O + stats)\n","\n","def _ensure_dir(p: str):\n","    Path(p).mkdir(parents=True, exist_ok=True)\n","\n","def load_test_data(data_type: str, num_examples: int = None) -> List[str]:\n","    \"\"\"\n","    Load toxic texts for a given data_type.\n","    Uses XDetox's datasets folder and simple heuristics for text column.\n","    \"\"\"\n","    if data_type not in data_configs:\n","        raise ValueError(f\"Unknown data_type: {data_type}\")\n","\n","    cfg = data_configs[data_type]\n","    data_path = os.path.join(REPO, cfg[\"data_path\"].lstrip(\"./\"))\n","\n","    texts = []\n","\n","    if cfg[\"format\"] == \"txt\":\n","        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n","            texts = [line.strip() for line in f if line.strip()]\n","\n","    elif cfg[\"format\"] == \"csv\":\n","        df = pd.read_csv(data_path)\n","        if \"text\" in df.columns:\n","            texts = df[\"text\"].tolist()\n","        elif \"toxic\" in df.columns:\n","            texts = df[\"toxic\"].tolist()\n","        else:\n","            texts = df.iloc[:, 0].tolist()\n","\n","    elif cfg[\"format\"] == \"tsv\":\n","        df = pd.read_csv(data_path, sep=\"\\t\")\n","        if \"text\" in df.columns:\n","            texts = df[\"text\"].tolist()\n","        else:\n","            texts = df.iloc[:, 0].tolist()\n","\n","    cleaned = []\n","    for t in texts:\n","        if pd.isna(t):\n","            continue\n","        s = str(t).strip()\n","        if s:\n","            cleaned.append(s)\n","\n","    if num_examples and num_examples > 0:\n","        cleaned = cleaned[:num_examples]\n","\n","    return cleaned\n","\n","def _safe_float(x):\n","    try:\n","        return float(x)\n","    except Exception:\n","        return float(\"nan\")\n","\n","def _read_stats_file(path: str):\n","    out = {}\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            if \":\" not in line:\n","                continue\n","            k, v = line.strip().split(\": \", 1)\n","            k = k.replace(\"(skipped)\", \"\").strip().lower()\n","            out[k] = _safe_float(v)\n","    return out\n","\n","print(\"Helper functions loaded\")\n"]},{"cell_type":"markdown","metadata":{"id":"46DzAjmRDqtD"},"source":["## T5 Model Loading"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBB3tCUsDqtE","executionInfo":{"status":"ok","timestamp":1764841752908,"user_tz":480,"elapsed":19862,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"8c17344c-fe8d-4a6c-a64d-ff8ac380e048"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading T5 model from /content/drive/MyDrive/w266 - Project/t5-base-detox-model...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["T5 model loaded on cuda\n"]}],"source":["#@title Load T5 model (ParaDetox)\n","\n","print(f\"Loading T5 model from {T5_CHECKPOINT}...\")\n","t5_tokenizer = T5Tokenizer.from_pretrained(T5_CHECKPOINT)\n","t5_model = T5ForConditionalGeneration.from_pretrained(T5_CHECKPOINT)\n","t5_model.eval()\n","\n","DEVICE_T5 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","t5_model.to(DEVICE_T5)\n","\n","print(f\"T5 model loaded on {DEVICE_T5}\")"]},{"cell_type":"markdown","metadata":{"id":"pxO0_6kaDqtE"},"source":["## T5 Multi-Candidate Generation"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8ePq3NTDqtE","executionInfo":{"status":"ok","timestamp":1764841764123,"user_tz":480,"elapsed":11210,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"3fa1dd6b-973f-420d-fc96-32d613814c41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: This is a stupid idea\n","  cand[0]: This is not a good idea.\n","  cand[1]: This is not good idea.\n","  cand[2]: This is a bad idea\n"]}],"source":["#@title T5 multi-candidate generation\n","\n","def t5_generate_candidates(\n","    text: str,\n","    model: T5ForConditionalGeneration,\n","    tokenizer: T5Tokenizer,\n","    num_candidates: int,\n","    temperature: float = 1.0,\n","    top_k: int = 50,\n","    top_p: float = 0.95,\n","    max_length: int = 128,\n","    device: torch.device = DEVICE_T5,\n",") -> List[str]:\n","    \"\"\"\n","    Generate num_candidates candidate rewrites via sampling.\n","    \"\"\"\n","    input_text = f\"detoxify: {text}\"\n","    input_ids = tokenizer.encode(\n","        input_text,\n","        return_tensors=\"pt\",\n","        max_length=max_length,\n","        truncation=True,\n","    ).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_return_sequences=num_candidates,\n","            do_sample=True,\n","            temperature=temperature,\n","            top_k=top_k,\n","            top_p=top_p,\n","            no_repeat_ngram_size=2,\n","        )\n","\n","    return [tokenizer.decode(out, skip_special_tokens=True) for out in outputs]\n","\n","def t5_generate_candidates_batch(\n","    texts: List[str],\n","    model: T5ForConditionalGeneration,\n","    tokenizer: T5Tokenizer,\n","    num_candidates: int,\n","    temperature: float = 1.0,\n","    top_k: int = 50,\n","    top_p: float = 0.95,\n","    max_length: int = 128,\n","    device: torch.device = DEVICE_T5,\n",") -> List[List[str]]:\n","    \"\"\"\n","    Batch generation of candidates for many inputs.\n","    \"\"\"\n","    all_candidates: List[List[str]] = []\n","    for text in tqdm(texts, desc=\"T5 Generation\"):\n","        cands = t5_generate_candidates(\n","            text,\n","            model,\n","            tokenizer,\n","            num_candidates=num_candidates,\n","            temperature=temperature,\n","            top_k=top_k,\n","            top_p=top_p,\n","            max_length=max_length,\n","            device=device,\n","        )\n","        all_candidates.append(cands)\n","    return all_candidates\n","\n","# Quick sanity check\n","test_text = \"This is a stupid idea\"\n","candidates = t5_generate_candidates(\n","    test_text,\n","    t5_model,\n","    t5_tokenizer,\n","    num_candidates=3,\n","    device=DEVICE_T5,\n",")\n","print(f\"Input: {test_text}\")\n","for i, c in enumerate(candidates):\n","    print(f\"  cand[{i}]: {c}\")"]},{"cell_type":"markdown","metadata":{"id":"K9HHeb4TDqtE"},"source":["## Global Reranking Functions"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1QWmTAADqtE","executionInfo":{"status":"ok","timestamp":1764841764147,"user_tz":480,"elapsed":12,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"b09428e4-2e14-4c2f-a246-fc1954bdaf79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Scoring device: cuda\n","Scoring model loaders ready\n"]}],"source":["#@title Global reranking models (toxicity, similarity, fluency)\n","\n","DEVICE_SCORE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Scoring device:\", DEVICE_SCORE)\n","\n","# Toxicity model (XLM-R large, same as before)\n","_TOX_MODEL_NAME = \"textdetox/xlmr-large-toxicity-classifier-v2\"\n","_TOX_TOKENIZER = None\n","_TOX_MODEL = None\n","\n","def _lazy_load_tox():\n","    global _TOX_TOKENIZER, _TOX_MODEL\n","    if _TOX_MODEL is None:\n","        print(\"Loading toxicity model...\")\n","        _TOX_TOKENIZER = AutoTokenizer.from_pretrained(_TOX_MODEL_NAME)\n","        _TOX_MODEL = AutoModelForSequenceClassification.from_pretrained(_TOX_MODEL_NAME)\n","        _TOX_MODEL.to(DEVICE_SCORE).eval()\n","\n","# Similarity model (LaBSE via AutoModel)\n","_LABSE_NAME = \"sentence-transformers/LaBSE\"\n","_LABSE_TOKENIZER = None\n","_LABSE_MODEL = None\n","\n","def _lazy_load_labse():\n","    global _LABSE_TOKENIZER, _LABSE_MODEL\n","    if _LABSE_MODEL is None:\n","        print(\"Loading LaBSE model...\")\n","        _LABSE_TOKENIZER = AutoTokenizer.from_pretrained(_LABSE_NAME)\n","        _LABSE_MODEL = AutoModel.from_pretrained(_LABSE_NAME).to(DEVICE_SCORE).eval()\n","\n","# Fluency model (GPT-2 small)\n","_GPT2_NAME = \"gpt2\"\n","_GPT2_TOK = None\n","_GPT2_MOD = None\n","\n","def _lazy_load_gpt2_scorer():\n","    global _GPT2_TOK, _GPT2_MOD\n","    if _GPT2_MOD is None:\n","        print(\"Loading GPT-2 model...\")\n","        _GPT2_TOK = GPT2TokenizerFast.from_pretrained(_GPT2_NAME)\n","        _GPT2_MOD = GPT2LMHeadModel.from_pretrained(_GPT2_NAME).to(DEVICE_SCORE).eval()\n","\n","print(\"Scoring model loaders ready\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2tBNrEjDqtE","executionInfo":{"status":"ok","timestamp":1764841764169,"user_tz":480,"elapsed":8,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"5ac470d1-4bcc-4335-b402-22aed3974599"},"outputs":[{"output_type":"stream","name":"stdout","text":["Global scoring functions defined\n"]}],"source":["#@title Global scoring functions (toxicity, similarity, fluency)\n","\n","@torch.no_grad()\n","def get_toxicity_scores(texts: List[str], batch_size: int = 32) -> List[float]:\n","    \"\"\"\n","    Toxicity probabilities in [0,1] (higher = more toxic).\n","    \"\"\"\n","    _lazy_load_tox()\n","    scores: List[float] = []\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"Toxicity\", leave=False):\n","        batch = texts[i:i + batch_size]\n","        enc = _TOX_TOKENIZER(\n","            batch,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            max_length=512,\n","            padding=True,\n","        ).to(DEVICE_SCORE)\n","        logits = _TOX_MODEL(**enc).logits\n","        probs = torch.softmax(logits, dim=-1)\n","        scores.extend(probs[:, 1].cpu().tolist())\n","    return scores\n","\n","@torch.no_grad()\n","def get_labse_embeddings(texts: List[str], batch_size: int = 32) -> np.ndarray:\n","    \"\"\"\n","    Mean-pooled LaBSE sentence embeddings.\n","    \"\"\"\n","    _lazy_load_labse()\n","    embs: List[np.ndarray] = []\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"LaBSE embeddings\", leave=False):\n","        batch = texts[i:i + batch_size]\n","        enc = _LABSE_TOKENIZER(\n","            batch,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            max_length=256,\n","            padding=True,\n","        ).to(DEVICE_SCORE)\n","        outputs = _LABSE_MODEL(**enc)\n","        hidden = outputs.last_hidden_state      # [B, L, H]\n","        mask = enc[\"attention_mask\"].unsqueeze(-1)  # [B, L, 1]\n","        masked = hidden * mask\n","        summed = masked.sum(dim=1)             # [B, H]\n","        counts = mask.sum(dim=1).clamp(min=1e-6)\n","        sent_emb = (summed / counts).cpu().numpy()\n","        embs.append(sent_emb)\n","    if not embs:\n","        return np.zeros((0, 768), dtype=np.float32)\n","    return np.vstack(embs)\n","\n","@torch.no_grad()\n","def get_gpt2_perplexities(texts: List[str]) -> List[float]:\n","    \"\"\"\n","    Approximate sentence-level perplexity with GPT-2.\n","    \"\"\"\n","    _lazy_load_gpt2_scorer()\n","    ppls: List[float] = []\n","    for s in tqdm(texts, desc=\"GPT-2 PPL\", leave=False):\n","        enc = _GPT2_TOK(s, return_tensors=\"pt\").to(DEVICE_SCORE)\n","        out = _GPT2_MOD(enc[\"input_ids\"], labels=enc[\"input_ids\"])\n","        ppl = math.exp(out.loss.item())\n","        if ppl > 1e4:\n","            ppl = 1e4\n","        ppls.append(float(ppl))\n","    return ppls\n","\n","def perplexity_to_fluency(ppls: List[float],\n","                          p_min: float = 5.0,\n","                          p_max: float = 300.0) -> np.ndarray:\n","    \"\"\"\n","    Map perplexities to [0,1] fluency scores.\n","    Low perplexity -> high fluency.\n","    \"\"\"\n","    p = np.asarray(ppls, dtype=float)\n","    p = np.clip(p, p_min, p_max)\n","    log_p = np.log(p)\n","    log_min = math.log(p_min)\n","    log_max = math.log(p_max)\n","    F = (log_max - log_p) / (log_max - log_min + 1e-8)\n","    F = np.clip(F, 0.0, 1.0)\n","    return F\n","\n","print(\"Global scoring functions defined\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"544kWFPdDqtE","executionInfo":{"status":"ok","timestamp":1764841764191,"user_tz":480,"elapsed":20,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"c063e634-ec2b-41a6-85d7-669845416547"},"outputs":[{"output_type":"stream","name":"stdout","text":["Global reranking function defined\n"]}],"source":["#@title Global reranking\n","\n","def rerank_candidates_global(\n","    sources: List[str],\n","    candidates: List[List[str]],\n","    weights: Tuple[float, float, float] = (0.5, 0.3, 0.2),\n",") -> List[str]:\n","    \"\"\"\n","    Global reranking:\n","      Score = w_T * (1 - toxicity) + w_S * similarity + w_F * fluency.\n","\n","    Args:\n","        sources:   list of input toxic sentences, length N\n","        candidates: list of list of candidates, shape [N][C]\n","        weights:   (w_toxicity, w_similarity, w_fluency)\n","\n","    Returns:\n","        best_candidates: list[str] length N\n","    \"\"\"\n","    w_T, w_S, w_F = weights\n","    N = len(sources)\n","    assert len(candidates) == N, \"candidates length mismatch\"\n","\n","    if N == 0:\n","        return []\n","\n","    C_list = [len(c) for c in candidates]\n","    C = C_list[0]\n","    assert all(c == C for c in C_list), \"All inputs must have same num_candidates\"\n","\n","    # Flatten candidates\n","    flat = [cand for clist in candidates for cand in clist]\n","    flat_idx = np.repeat(np.arange(N), C)\n","\n","    print(\"  Computing toxicity scores...\")\n","    tox = np.array(get_toxicity_scores(flat))   # higher = more toxic\n","    safety = 1.0 - tox\n","\n","    print(\"  Computing similarity scores (LaBSE)...\")\n","    src_embs = get_labse_embeddings(sources)\n","    cand_embs = get_labse_embeddings(flat)\n","\n","    # Normalize\n","    src_embs = src_embs / np.linalg.norm(src_embs, axis=1, keepdims=True).clip(1e-8)\n","    cand_embs = cand_embs / np.linalg.norm(cand_embs, axis=1, keepdims=True).clip(1e-8)\n","\n","    sims = np.sum(cand_embs * src_embs[flat_idx], axis=1)  # cosine\n","    sims = (sims + 1.0) / 2.0  # to [0,1]\n","\n","    print(\"  Computing fluency scores (GPT-2)...\")\n","    ppls = get_gpt2_perplexities(flat)\n","    flus = perplexity_to_fluency(ppls)\n","\n","    scores = w_T * safety + w_S * sims + w_F * flus\n","    scores = scores.reshape(N, C)\n","\n","    best_idx = scores.argmax(axis=1)\n","    best = [candidates[i][best_idx[i]] for i in range(N)]\n","    return best\n","\n","print(\"Global reranking function defined\")"]},{"cell_type":"markdown","metadata":{"id":"YO4eCqW_DqtE"},"source":["## Evaluation Functions"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"azibo8CBDqtE","executionInfo":{"status":"ok","timestamp":1764841764227,"user_tz":480,"elapsed":33,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"e6cf4443-ed5b-4c12-bb07-e6a2d365dc21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation helpers (evaluate_all) defined\n"]}],"source":["#@title Evaluation helpers — call evaluation/evaluate_all.py (XDetox)\n","\n","def _eval_with_toxicity(base_path: str,\n","                        overwrite_eval: bool = False,\n","                        skip_ref: bool = False,\n","                        tox_threshold: float = 0.5,\n","                        tox_batch_size: int = 32):\n","    \"\"\"\n","    Call evaluation.evaluate_all on each run folder in base_path.\n","    This matches the LLM pipeline behaviour.\n","    \"\"\"\n","    import sys as _sys\n","    for folder in os.listdir(base_path):\n","        gen_dir  = os.path.join(base_path, folder)\n","        if not os.path.isdir(gen_dir):\n","            continue\n","        orig_path = os.path.join(gen_dir, \"orig.txt\")\n","        gen_path  = os.path.join(gen_dir, \"gen.txt\")\n","        out_stats = os.path.join(gen_dir, \"gen_stats.txt\")\n","        if not (os.path.exists(orig_path) and os.path.exists(gen_path)):\n","            continue\n","        if os.path.exists(out_stats) and not overwrite_eval:\n","            continue\n","\n","        env = os.environ.copy()\n","        env[\"PYTHONPATH\"] = REPO + (\n","            \":\" + env.get(\"PYTHONPATH\", \"\") if env.get(\"PYTHONPATH\") else \"\"\n","        )\n","\n","        cmd = [\n","            _sys.executable, \"-m\", \"evaluation.evaluate_all\",\n","            \"--orig_path\", orig_path,\n","            \"--gen_path\",  gen_path,\n","            \"--tox_threshold\", str(tox_threshold),\n","            \"--tox_batch_size\", str(tox_batch_size),\n","        ]\n","        if skip_ref:\n","            cmd.append(\"--skip_ref\")\n","\n","        print(\"Eval:\", \" \".join(cmd))\n","        res = run(\n","            cmd,\n","            cwd=REPO,\n","            env=env,\n","            stdout=PIPE,\n","            stderr=PIPE,\n","            text=True,\n","        )\n","        if res.returncode != 0:\n","            print(res.stdout)\n","            print(res.stderr)\n","            res.check_returncode()\n","\n","def _aggregate_eval_csv(output_folder: str,\n","                        data_type: str,\n","                        base_out_dir: str):\n","    \"\"\"\n","    Aggregate eval metrics for T5 + Global reranking.\n","\n","    Layout:\n","      base_out_dir/\n","        └── {data_type}/\n","            └── T5_Global_Rerank/\n","                └── {run_folder}/\n","                    └── gen_stats.txt\n","\n","    Writes:\n","      base_out_dir/{data_type}/{data_type}.csv\n","    \"\"\"\n","    rows = []\n","\n","    rerank_dir = \"T5_Global_Rerank\"\n","    base_path  = os.path.join(base_out_dir, data_type, rerank_dir)\n","    if not os.path.isdir(base_path):\n","        print(\"No evaluation directory found:\", base_path)\n","        return\n","\n","    for folder in os.listdir(base_path):\n","        gen_dir   = os.path.join(base_path, folder)\n","        stats_path = os.path.join(gen_dir, \"gen_stats.txt\")\n","        if not os.path.exists(stats_path):\n","            continue\n","        s = _read_stats_file(stats_path)\n","        rows.append({\n","            # label column; not a real threshold here, but kept for compatibility\n","            \"config\":          folder,\n","            \"bertscore\":       s.get(\"bertscore\", np.nan),\n","            \"meaningbert\":     s.get(\"meaningbert\", np.nan),\n","            \"bleu4\":           s.get(\"bleu4\", np.nan),\n","            \"perplexity_gen\":  s.get(\"perplexity gen\", np.nan),\n","            \"perplexity_orig\": s.get(\"perplexity orig\", np.nan),\n","            \"toxicity_gen\":    s.get(\"toxicity gen\", np.nan),\n","            \"toxicity_orig\":   s.get(\"toxicity orig\", np.nan),\n","        })\n","\n","    if rows:\n","        cols = [\n","            \"config\",\n","            \"bertscore\", \"meaningbert\", \"bleu4\",\n","            \"perplexity_gen\", \"perplexity_orig\",\n","            \"toxicity_gen\", \"toxicity_orig\",\n","        ]\n","        df = pd.DataFrame(rows)\n","        df = df[cols]\n","        out_csv = os.path.join(base_out_dir, data_type, f\"{data_type}.csv\")\n","        df.to_csv(out_csv, index=False)\n","        print(\"Wrote summary CSV:\", out_csv)\n","    else:\n","        print(\"No evaluation files found to summarize.\")\n","\n","print(\"Evaluation helpers (evaluate_all) defined\")"]},{"cell_type":"code","source":["#@title Helpers for folder naming\n","\n","def _bool2str(x: bool) -> str:\n","    return \"T\" if x else \"F\"\n","\n","def _build_run_folder_name_t5_global(\n","    num_candidates: int,\n","    max_length: int,\n","    temperature: float,\n","    top_k: int,\n","    top_p: float,\n","    w_T: float,\n","    w_S: float,\n","    w_F: float,\n",") -> str:\n","    \"\"\"\n","    Encode T5 + Global hyperparameters into a folder name.\n","    \"\"\"\n","    return (\n","        f\"t5_nc{num_candidates}_maxlen{max_length}_\"\n","        f\"temp{temperature}_topk{top_k}_topp{top_p}_\"\n","        f\"wT{w_T}_wS{w_S}_wF{w_F}\"\n","    )"],"metadata":{"id":"dC7ObJEowF_P","executionInfo":{"status":"ok","timestamp":1764841764232,"user_tz":480,"elapsed":3,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fun3iedKDqtF"},"source":["## Main Pipeline Function"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flbmhXsiDqtF","executionInfo":{"status":"ok","timestamp":1764841764257,"user_tz":480,"elapsed":22,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"b62790e3-3592-408f-8ca6-36cf2f2bca32"},"outputs":[{"output_type":"stream","name":"stdout","text":["detoxify() defined\n"]}],"source":["#@title detoxify() — T5 + Global reranking + evaluate_all\n","\n","def detoxify(\n","    data_type: str = \"paradetox\",\n","    output_folder: str = \"T5_w_Global-Reranking\",\n","    echo: bool = False,\n","    num_examples: int = 1000,\n","    num_candidates: int = 10,\n","    max_length: int = 128,\n","    temperature: float = 1.0,\n","    top_k: int = 50,\n","    top_p: float = 0.95,\n","    weights: Tuple[float, float, float] = (0.5, 0.3, 0.2),\n","    overwrite_gen: bool = False,\n","    run_eval: bool = True,\n","    overwrite_eval: bool = False,\n","    skip_ref_eval: bool = False,\n","):\n","    \"\"\"\n","    T5-ParaDetox pipeline:\n","\n","      1. Generate num_candidates detoxified texts per input using T5 sampling.\n","      2. Global reranking with toxicity + similarity + fluency.\n","      3. Save orig/gen under XDetox/data/model_outputs/{output_folder}/{data_type}/T5_Global_Rerank/{run_folder}.\n","      4. Run evaluation via evaluation.evaluate_all (BLEU, BERTScore, MeaningBERT, PPL, Toxicity).\n","      5. Aggregate into per-dataset CSV (same style as LLM pipelines).\n","\n","    Returns:\n","        If run_eval: dict of metrics for this run (parsed from gen_stats.txt).\n","        Else: None.\n","    \"\"\"\n","    assert data_type in data_configs, f\"Unknown data_type: {data_type}\"\n","\n","    # Output base (relative to repo, as in LLM pipeline)\n","    base_out_rel = os.path.join(\"data\", \"model_outputs\", output_folder)\n","    base_out_abs = os.path.join(REPO, base_out_rel)\n","    _ensure_dir(base_out_abs)\n","\n","    # Load inputs\n","    print(\"=\" * 80)\n","    print(f\"[{data_type}] Loading data...\")\n","    orig_texts = load_test_data(data_type, num_examples)\n","    print(f\"  Loaded {len(orig_texts)} examples\")\n","\n","    if echo:\n","        print(\"\\n[echo] Example inputs (first up to 3):\")\n","        for i, s in enumerate(orig_texts[:3]):\n","            print(f\"  input[{i}]: {s}\")\n","        print(f\"\\n[echo] Global weights (tox, sim, flu): {weights}\")\n","\n","    # Current pipeline directory (T5 + Global)\n","    rerank_dir = \"T5_Global_Rerank\"\n","    cur_rel = os.path.join(base_out_rel, data_type, rerank_dir)\n","    cur_abs = os.path.join(REPO, cur_rel)\n","    _ensure_dir(cur_abs)\n","\n","    # Folder name for this configuration\n","    w_T, w_S, w_F = weights\n","    run_folder = _build_run_folder_name_t5_global(\n","        num_candidates=num_candidates,\n","        max_length=max_length,\n","        temperature=temperature,\n","        top_k=top_k,\n","        top_p=top_p,\n","        w_T=w_T,\n","        w_S=w_S,\n","        w_F=w_F,\n","    )\n","    final_abs = os.path.join(cur_abs, run_folder)\n","    _ensure_dir(final_abs)\n","\n","    orig_path = os.path.join(final_abs, \"orig.txt\")\n","    gen_path  = os.path.join(final_abs, \"gen.txt\")\n","    stats_path = os.path.join(final_abs, \"gen_stats.txt\")\n","\n","    # Generate or load gen.txt\n","    if overwrite_gen or not os.path.exists(gen_path):\n","        print(\"  Generating candidates with T5...\")\n","        all_candidates = t5_generate_candidates_batch(\n","            orig_texts,\n","            t5_model,\n","            t5_tokenizer,\n","            num_candidates=num_candidates,\n","            temperature=temperature,\n","            top_k=top_k,\n","            top_p=top_p,\n","            max_length=max_length,\n","            device=DEVICE_T5,\n","        )\n","\n","        if echo and all_candidates:\n","            print(\"\\n[echo] Example candidates for input[0]:\")\n","            for j, c in enumerate(all_candidates[0][:3]):\n","                print(f\"    cand[{j}]: {c}\")\n","\n","        print(\"  Global reranking (toxicity + similarity + fluency)...\")\n","        gen_texts = rerank_candidates_global(\n","            sources=orig_texts,\n","            candidates=all_candidates,\n","            weights=weights,\n","        )\n","\n","        if echo:\n","            print(\"\\n[echo] Selected outputs (first up to 3):\")\n","            for i, g in enumerate(gen_texts[:3]):\n","                print(f\"  output[{i}]: {g}\")\n","\n","        # Save orig and gen\n","        with open(orig_path, \"w\") as f:\n","            for t in orig_texts:\n","                f.write(re.sub(r\"\\s+\", \" \", t).strip() + \"\\n\")\n","\n","        with open(gen_path, \"w\") as f:\n","            for t in gen_texts:\n","                f.write(re.sub(r\"\\s+\", \" \", t).strip() + \"\\n\")\n","\n","        print(\"  Saved orig/gen to:\", final_abs)\n","    else:\n","        print(\"  Reusing existing orig/gen from:\", final_abs)\n","        with open(orig_path, \"r\") as f:\n","            orig_texts = [l.strip() for l in f]\n","        with open(gen_path, \"r\") as f:\n","            gen_texts = [l.strip() for l in f]\n","        print(f\"  Loaded {len(gen_texts)} generated examples\")\n","\n","    # Evaluation via evaluation/evaluate_all.py\n","    metrics = None\n","    if run_eval:\n","        base_path = os.path.join(base_out_abs, data_type, rerank_dir)\n","        _eval_with_toxicity(\n","            base_path,\n","            overwrite_eval=overwrite_eval,\n","            skip_ref=skip_ref_eval,\n","            tox_threshold=0.5,\n","            tox_batch_size=32,\n","        )\n","        _aggregate_eval_csv(\n","            output_folder,\n","            data_type,\n","            os.path.join(REPO, \"data\", \"model_outputs\", output_folder),\n","        )\n","\n","        if os.path.exists(stats_path):\n","            metrics = _read_stats_file(stats_path)\n","            if echo:\n","                print(\"\\n[echo] Evaluation metrics for this run:\")\n","                for k, v in metrics.items():\n","                    if isinstance(v, float) and math.isnan(v):\n","                        continue\n","                    print(f\"  {k}: {v:.4f}\")\n","        else:\n","            print(\"  gen_stats.txt not found for this run; no metrics to print.\")\n","\n","    print(\"=\" * 80)\n","    return metrics\n","\n","print(\"detoxify() defined\")"]},{"cell_type":"markdown","metadata":{"id":"t7CJKK63DqtF"},"source":["## Run Evaluation"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["13d8250dabae463e87cf53aa8c499ef7","bbbd2a42d692433caf4f8e61319fc829","95e6a6496e544d38a808e269f03da4eb","a4a7fe8d6c254e9baf0e14b4b2feaa2a","13045bb8238d43819cc21cb601ebbaf8","b11f9bd1a68548838d2371651353b837","aaf102b9b3004997ab8841c925229e98","142cc10c08e54dce8397dd56eb5f01ae","7d4e58cc74744b09bb16fe7bf7276837","913e16e91005482987264182841b4423","d597ee471c664ea0a2514b4811369333","942765e4194340a4a96d274bab490ad4","93e274e4dd4743af853d2667b9d28b75","372f635e1a004be4bd58a4b426a47e36","176a3650438d4d3091abd27c668a6ee0","68ce2cd819444034bdc81fb5f8c86879","f89e2c3a4e524894a3df46df5367a220","a937c004203f44218ed4934dd9415bf7","49ecc86cf13346bab6cd72fe62fddf10","a2956df0d1d64490afed6ef5eb441c12","18fb6598753147b4b79e82e80c9abfd7","532320f8a98b4c1e910b0c30f5c9bc6c","cbbae909939c4163bb1f3b29fbbbbd9a","8e8f75d0474d4ba0b16abb9511d4c0f9","50d0aad28f604a12b6899de774884192","9b59d658cb38415889754cfe58c03ded","995b9fb6259241c4bc62db7c88bb62c7","60611123d7d7436baab7a5767832de93","a6ca9867cec94e14bce60b85ca225457","24176d46687f43eabbacbaf812a6f4bd","9a7a531ca27343acbee025be329bc11c","be9ccede600942c09a2d86a1b27acea5","ce5379fc0c274cd1948e1cf4f01f8814","a76f85aaa1004703b4c3b31f6543841e","8ee342c3fff44690bb068783f0431994","3dc8afb9213242bea9f49aa61bc97edf","5e09d35bcede43068e9af39fee0767a3","58ea7f722318429a8c4e8d46d94ac3f3","36ff333573cb4ee880ad50fe3c1c57fb","dc904ef1095d468192a0031f4f04bb6d","cae77cf5e94d497e93d05da554c762d7","50eaa6aac5d54eeba1b9774408c47ac2","aed201d09cd74a01a685bf0842efa94d","b32d22b8b754435080e93da4ed6d9fba","19d720774c93454bb96b166a1e8f63c8","d4bfdde286f943baadbbd6b6144e0af1","0a2a2da5cfb1485b9079c3b704d7f281","9863ca0078a34d39a51e826b4088e1c8","466ebd10fc2245cfae09574e52dd10fe","9b2bc71dfd424e9ea134f75a9783c10a","58386957060e4345bcf2f47347eabf44","1db7eb487ff240e7a3b44aef804612e9","cc05f95a3a1041cb80b45c72fc776987","9ab30a79ec0043b5b4973418ca07c088","5c30373cdb694f06886977bdf3a9b144"]},"id":"0Adk9uM1DqtF","executionInfo":{"status":"ok","timestamp":1764842840229,"user_tz":480,"elapsed":1075976,"user":{"displayName":"Kent Bourgoing","userId":"01773768369839516808"}},"outputId":"9efbb5f7-7c55-4b3c-f104-ab1a67522b5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","[paradetox] Loading data...\n","  Loaded 671 examples\n","\n","[echo] Example inputs (first up to 3):\n","  input[0]: . or the loud ass one - thousand ton beast roaring towards you howling its horn .\n","  input[1]: mandated  and \" right fucking now \" would be good .\n","  input[2]: * neither * of my coworkers gave a shit when it came time to ditch mitch . ugh .\n","\n","[echo] Global weights (tox, sim, flu): (0.5, 0.3, 0.2)\n","  Generating candidates with T5...\n"]},{"output_type":"display_data","data":{"text/plain":["T5 Generation:   0%|          | 0/671 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d8250dabae463e87cf53aa8c499ef7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","[echo] Example candidates for input[0]:\n","    cand[0]: or the one thousand ton beast roaring towards you howling its horn\n","    cand[1]: Or the one thousand ton beast roaring towards you\n","    cand[2]: or the one thousand ton beast roaring towards you howling its horn .\n","  Global reranking (toxicity + similarity + fluency)...\n","  Computing toxicity scores...\n","Loading toxicity model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Toxicity:   0%|          | 0/210 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942765e4194340a4a96d274bab490ad4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  Computing similarity scores (LaBSE)...\n","Loading LaBSE model...\n"]},{"output_type":"display_data","data":{"text/plain":["LaBSE embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbbae909939c4163bb1f3b29fbbbbd9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["LaBSE embeddings:   0%|          | 0/210 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a76f85aaa1004703b4c3b31f6543841e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  Computing fluency scores (GPT-2)...\n","Loading GPT-2 model...\n"]},{"output_type":"display_data","data":{"text/plain":["GPT-2 PPL:   0%|          | 0/6710 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d720774c93454bb96b166a1e8f63c8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","[echo] Selected outputs (first up to 3):\n","  output[0]: or the loud one- thousand ton beast roaring toward you howling its horn .\n","  output[1]: mandated and \"right now\" would be good.\n","  output[2]: neither one of my coworkers cared when it came time to ditch mitch\n","  Saved orig/gen to: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_w_Global-Reranking - KB/paradetox/T5_Global_Rerank/t5_nc10_maxlen128_temp1.0_topk50_topp0.95_wT0.5_wS0.3_wF0.2\n","Eval: /usr/bin/python3 -m evaluation.evaluate_all --orig_path /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_w_Global-Reranking - KB/paradetox/T5_Global_Rerank/t5_nc10_maxlen128_temp1.0_topk50_topp0.95_wT0.5_wS0.3_wF0.2/orig.txt --gen_path /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_w_Global-Reranking - KB/paradetox/T5_Global_Rerank/t5_nc10_maxlen128_temp1.0_topk50_topp0.95_wT0.5_wS0.3_wF0.2/gen.txt --tox_threshold 0.5 --tox_batch_size 32\n","Wrote summary CSV: /content/drive/MyDrive/w266 - Project/XDetox/data/model_outputs/T5_w_Global-Reranking - KB/paradetox/paradetox.csv\n","\n","[echo] Evaluation metrics for this run:\n","  bertscore: 0.9355\n","  meaningbert: 67.2540\n","  bleu4: 53.3350\n","  toxicity gen: 0.0515\n","  perplexity gen: 171.5300\n","  toxicity orig: 0.9253\n","  perplexity orig: 273.7500\n","  percent toxic gen: 0.0477\n","  percent toxic ref: 0.9285\n","================================================================================\n","\n","Paradetox metrics for this run:\n","  bertscore: 0.9355\n","  meaningbert: 67.2540\n","  bleu4: 53.3350\n","  toxicity gen: 0.0515\n","  perplexity gen: 171.5300\n","  toxicity orig: 0.9253\n","  perplexity orig: 273.7500\n","  percent toxic gen: 0.0477\n","  percent toxic ref: 0.9285\n"]}],"source":["#@title Example run — paradetox\n","\n","metrics_paradetox = detoxify(\n","    data_type=\"paradetox\",\n","    output_folder=\"T5_w_Global-Reranking - KB\",\n","    echo=True,\n","    num_examples=1000,\n","    num_candidates=10,\n","    max_length=128,\n","    temperature=1.0,\n","    top_k=50,\n","    top_p=0.95,\n","    weights=(0.5, 0.3, 0.2),\n","    overwrite_gen=True,\n","    run_eval=True,\n","    overwrite_eval=True,\n","    skip_ref_eval=False,\n",")\n","\n","print(\"\\nParadetox metrics for this run:\")\n","if metrics_paradetox:\n","    for k, v in metrics_paradetox.items():\n","        if isinstance(v, float) and math.isnan(v):\n","            continue\n","        print(f\"  {k}: {v:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"13d8250dabae463e87cf53aa8c499ef7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbbd2a42d692433caf4f8e61319fc829","IPY_MODEL_95e6a6496e544d38a808e269f03da4eb","IPY_MODEL_a4a7fe8d6c254e9baf0e14b4b2feaa2a"],"layout":"IPY_MODEL_13045bb8238d43819cc21cb601ebbaf8"}},"bbbd2a42d692433caf4f8e61319fc829":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b11f9bd1a68548838d2371651353b837","placeholder":"​","style":"IPY_MODEL_aaf102b9b3004997ab8841c925229e98","value":"T5 Generation: 100%"}},"95e6a6496e544d38a808e269f03da4eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_142cc10c08e54dce8397dd56eb5f01ae","max":671,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d4e58cc74744b09bb16fe7bf7276837","value":671}},"a4a7fe8d6c254e9baf0e14b4b2feaa2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_913e16e91005482987264182841b4423","placeholder":"​","style":"IPY_MODEL_d597ee471c664ea0a2514b4811369333","value":" 671/671 [04:33&lt;00:00,  3.16it/s]"}},"13045bb8238d43819cc21cb601ebbaf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11f9bd1a68548838d2371651353b837":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf102b9b3004997ab8841c925229e98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"142cc10c08e54dce8397dd56eb5f01ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d4e58cc74744b09bb16fe7bf7276837":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"913e16e91005482987264182841b4423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d597ee471c664ea0a2514b4811369333":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"942765e4194340a4a96d274bab490ad4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93e274e4dd4743af853d2667b9d28b75","IPY_MODEL_372f635e1a004be4bd58a4b426a47e36","IPY_MODEL_176a3650438d4d3091abd27c668a6ee0"],"layout":"IPY_MODEL_68ce2cd819444034bdc81fb5f8c86879"}},"93e274e4dd4743af853d2667b9d28b75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f89e2c3a4e524894a3df46df5367a220","placeholder":"​","style":"IPY_MODEL_a937c004203f44218ed4934dd9415bf7","value":"Toxicity: 100%"}},"372f635e1a004be4bd58a4b426a47e36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_49ecc86cf13346bab6cd72fe62fddf10","max":210,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2956df0d1d64490afed6ef5eb441c12","value":210}},"176a3650438d4d3091abd27c668a6ee0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18fb6598753147b4b79e82e80c9abfd7","placeholder":"​","style":"IPY_MODEL_532320f8a98b4c1e910b0c30f5c9bc6c","value":" 209/210 [00:30&lt;00:00,  7.87it/s]"}},"68ce2cd819444034bdc81fb5f8c86879":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f89e2c3a4e524894a3df46df5367a220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a937c004203f44218ed4934dd9415bf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49ecc86cf13346bab6cd72fe62fddf10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2956df0d1d64490afed6ef5eb441c12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18fb6598753147b4b79e82e80c9abfd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"532320f8a98b4c1e910b0c30f5c9bc6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbbae909939c4163bb1f3b29fbbbbd9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e8f75d0474d4ba0b16abb9511d4c0f9","IPY_MODEL_50d0aad28f604a12b6899de774884192","IPY_MODEL_9b59d658cb38415889754cfe58c03ded"],"layout":"IPY_MODEL_995b9fb6259241c4bc62db7c88bb62c7"}},"8e8f75d0474d4ba0b16abb9511d4c0f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60611123d7d7436baab7a5767832de93","placeholder":"​","style":"IPY_MODEL_a6ca9867cec94e14bce60b85ca225457","value":"LaBSE embeddings:  90%"}},"50d0aad28f604a12b6899de774884192":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_24176d46687f43eabbacbaf812a6f4bd","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a7a531ca27343acbee025be329bc11c","value":21}},"9b59d658cb38415889754cfe58c03ded":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be9ccede600942c09a2d86a1b27acea5","placeholder":"​","style":"IPY_MODEL_ce5379fc0c274cd1948e1cf4f01f8814","value":" 19/21 [00:01&lt;00:00, 20.11it/s]"}},"995b9fb6259241c4bc62db7c88bb62c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"60611123d7d7436baab7a5767832de93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ca9867cec94e14bce60b85ca225457":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24176d46687f43eabbacbaf812a6f4bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a7a531ca27343acbee025be329bc11c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be9ccede600942c09a2d86a1b27acea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce5379fc0c274cd1948e1cf4f01f8814":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a76f85aaa1004703b4c3b31f6543841e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ee342c3fff44690bb068783f0431994","IPY_MODEL_3dc8afb9213242bea9f49aa61bc97edf","IPY_MODEL_5e09d35bcede43068e9af39fee0767a3"],"layout":"IPY_MODEL_58ea7f722318429a8c4e8d46d94ac3f3"}},"8ee342c3fff44690bb068783f0431994":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36ff333573cb4ee880ad50fe3c1c57fb","placeholder":"​","style":"IPY_MODEL_dc904ef1095d468192a0031f4f04bb6d","value":"LaBSE embeddings: 100%"}},"3dc8afb9213242bea9f49aa61bc97edf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae77cf5e94d497e93d05da554c762d7","max":210,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50eaa6aac5d54eeba1b9774408c47ac2","value":210}},"5e09d35bcede43068e9af39fee0767a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aed201d09cd74a01a685bf0842efa94d","placeholder":"​","style":"IPY_MODEL_b32d22b8b754435080e93da4ed6d9fba","value":" 210/210 [00:08&lt;00:00, 28.97it/s]"}},"58ea7f722318429a8c4e8d46d94ac3f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"36ff333573cb4ee880ad50fe3c1c57fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc904ef1095d468192a0031f4f04bb6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae77cf5e94d497e93d05da554c762d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50eaa6aac5d54eeba1b9774408c47ac2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aed201d09cd74a01a685bf0842efa94d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b32d22b8b754435080e93da4ed6d9fba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19d720774c93454bb96b166a1e8f63c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4bfdde286f943baadbbd6b6144e0af1","IPY_MODEL_0a2a2da5cfb1485b9079c3b704d7f281","IPY_MODEL_9863ca0078a34d39a51e826b4088e1c8"],"layout":"IPY_MODEL_466ebd10fc2245cfae09574e52dd10fe"}},"d4bfdde286f943baadbbd6b6144e0af1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b2bc71dfd424e9ea134f75a9783c10a","placeholder":"​","style":"IPY_MODEL_58386957060e4345bcf2f47347eabf44","value":"GPT-2 PPL: 100%"}},"0a2a2da5cfb1485b9079c3b704d7f281":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1db7eb487ff240e7a3b44aef804612e9","max":6710,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc05f95a3a1041cb80b45c72fc776987","value":6710}},"9863ca0078a34d39a51e826b4088e1c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ab30a79ec0043b5b4973418ca07c088","placeholder":"​","style":"IPY_MODEL_5c30373cdb694f06886977bdf3a9b144","value":" 6705/6710 [01:24&lt;00:00, 83.03it/s]"}},"466ebd10fc2245cfae09574e52dd10fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"9b2bc71dfd424e9ea134f75a9783c10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58386957060e4345bcf2f47347eabf44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1db7eb487ff240e7a3b44aef804612e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc05f95a3a1041cb80b45c72fc776987":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ab30a79ec0043b5b4973418ca07c088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c30373cdb694f06886977bdf3a9b144":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}